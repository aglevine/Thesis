\def\bbbar{\ensuremath{\mathrm{b\bar{b}}}}
\def\ccbar{\ensuremath{\mathrm{c\bar{c}}}}
\newcommand{\PZ}{Z}
\newcommand{\ZZ}{ZZ}
\newcommand{\WW}{WW}
\newcommand{\WZ}{WZ}
\newcommand{\pp}{\Pp\Pp\xspace}
\newcommand{\Wjets}{\ensuremath{\PW+\text{jets}}\xspace}
\def\Wmnbb{\ensuremath{\mathrm{W}(\Pgm\cPgn)+\bbbar}}
\def\WmnH{\ensuremath{\mathrm{W}(\Pgm\cPgn)\mathrm{H}}}
\def\Wbb{\ensuremath{\mathrm{W+\bbbar}}}
\def\hbb{\ensuremath{\mathrm{W+h\rightarrow\bbbar}}}
\def\Wc{\ensuremath{\mathrm{W+c}}}
\def\Wmn{\ensuremath{\mathrm{W}\rightarrow \mu\nu}}
\def\Wln{\ensuremath{\mathrm{W}\rightarrow \ell\nu}}
\def\Wcc{\ensuremath{\mathrm{W+\ccbar}}}
\def\Zll{\ensuremath{\mathrm{Z\rightarrow\ell\ell}}}
\def\MT{M_\mathrm{T}}
\def\ET{$E_\mathrm{T}$}
\def\pt{p_\mathrm{T}}
\def\GeV{$\mathrm{GeV}$}
\def\TeV{$\mathrm{TeV}$}
\def\tev{$\mathrm{TeV}$}
\def\PYTHIA{$\mathtt{PYTHIA}$}
\def\POWHEG{$\mathtt{POWHEG}$}
\def\MADGRAPH{$\mathtt{MADGRAPH}$}
\def\GEANTfour{$\mathtt{GEANT4}$}
\def\TAUOLA{$\mathtt{TAUOLA}$}
\def\ptvec{$\vec{p_{T}}$}
\def\VEtmiss{$\vec{MET}$}
\def\La{\mathscr{L}}
\def\fbinv{fb^\mathrm{-1}}
\def\Pg{\mathrm{g}}
\def\Pp{\mathrm{p}}
\def\Pgt{\mathrm{\tau}}
\def\tauh{\mathrm{\tau_{h}}}
\def\Pgm{\mathrm{\mu}}
\def\Pe{\mathrm{e}}
\def\cPZ{\mathrm{Z}}
\def\PW{\mathrm{W}}
\def\pt{\mathrm{p_{T}}}
\def\cPqt{\mathrm{q}}
\def\cPaqt{\mathrm{\bar{q}}}%%%%%CHECK THIS
\def\Pg{$\mathrm{g}$}
\def\vecEtm{\overline{\slash{E_{T}}}}
\def\vecPtmu{\overline{p_{T}(\mu)}}
\def\MET{\slash{E_{T}}}
\def\ttbar{${t\bar{t}}$}
\def\vecEtm{\ensuremath{\vec{E}_\mathrm{T}^{\mathrm{miss}}}\;}
\def\MET{\ensuremath{E_\mathrm{T}^{\mathrm{miss}}}\;}
\def\vecPtmu{\ensuremath{\vec{P}_\mathrm{T}^{\mu}}\;}

\newcommand{\Lint}{\ensuremath{{\cal L}_{\mathrm{int}}}}
\newcommand{\dytt}{\ensuremath{\cPZ/\Pgg^*\to\tau^+\tau^-}}
\newcommand{\dyll}{\ensuremath{\cPZ/\Pgg^*\to \ell^+\ell^-}}
\newcommand{\stat}{\ensuremath{\,\mathrm{(stat.)\;}}}
\newcommand{\syst}{\ensuremath{\,\mathrm{(syst.)\;}}}
\newcommand{\lumi}{\ensuremath{\,\mathrm{(lum.)\;}}}
\newcommand{\theo}{\ensuremath{\,\mathrm{(theo.)}}\;}



\RequirePackage{lineno}
\documentclass[oneside, letterpaper, oldfontcommands]{memoir}
%\documentclass[oneside, letterpaper, 12pt, oldfontcommands]{article}


%%%% Import uwthesis.sty to get official formatting, then set your variables.
%\usepackage{uwthesis}
%% Set the upper and lower margins (automatically adjust the textblock)
%% Upper margin needs to be larger than 1in to allow room for the page number
\setulmarginsandblock{1.5in}{1in}{*}
%% Left margin is a little larger to allow room for binding
%% Set the left and right margins (automatically adjust the textblock)
\setlrmarginsandblock{1.5in}{1in}{*}
%% Set the distance between the top of the page and the top of the header
%% The first argument is headdrop (distance from top of page to top of header)
\setheaderspaces{1in}{*}{*}
%% Implement the above changes
\checkandfixthelayout



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% INTERFACE (variables for the user to set)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% For the title/committee page
\newcommand{\settitle}[1]{\def\uwtitle{#1}}  % your title
\newcommand{\setauthor}[1]{\def\uwauthor{#1}} % you
\newcommand{\setdepartment}[1]{\def\uwdepartment{#1}}  % your title
\newcommand{\masters}{\def\uwdegree{Master of Arts}}
\newcommand{\doctors}{\def\uwdegree{Doctor of Philosophy}}
\newcommand{\setgraddate}[1]{\def\uwgraddate{#1}} % graduation date
\newcommand{\setdefensedate}[1]{\def\uwdefensedate{#1}} % defense date
\newcommand{\setabstract}[1]{\def\uwabstract{#1}} % abstract

%% Members of the Final Oral Committee
\newcommand{\setfoca}[3]{\def\uwfoca{#1}\def\uwranka{#2}\def\uwdepa{#3}}
\newcommand{\setfocb}[3]{\def\uwfocb{#1}\def\uwrankb{#2}\def\uwdepb{#3}}
\newcommand{\setfocc}[3]{\def\uwfocc{#1}\def\uwrankc{#2}\def\uwdepc{#3}}
\newcommand{\setfocd}[3]{\def\uwfocd{#1}\def\uwrankd{#2}\def\uwdepd{#3}}
\newcommand{\setfoce}[3]{\def\uwfoce{#1}\def\uwranke{#2}\def\uwdepe{#3}}
\newcommand{\setfocf}[3]{\def\uwfocf{#1}\def\uwrankf{#2}\def\uwdepf{#3}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% REFERENCES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Make the reference section single-spaced
\let\oldbib\bibliography
\renewcommand*{\bibliography}{\SingleSpace\oldbib}
\setlength{\bibitemsep}{\onelineskip}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% TITLE/COMMITTEE page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Command to determine how the members of the committee are formatted
\newcommand{\boxfoc}[3]{\makebox[0.4\textwidth][r]{#1} $\cdot$ \makebox[0.4\textwidth][l]{#2 of #3}}

%% Command to create the title page
\newcommand{\thetitlepage}{%
  \thispagestyle{empty}
  \begin{center}
    \vfill
    {\Large\sc\uwtitle\par}
    \vfill
    \emph{by} \\ 
    \uwauthor \\
    \vfill
    A dissertation submitted in partial fulfillment of \\
    the requirements for the degree of \\
    \vfill
    \uwdegree \\
    (\uwdepartment) \\
    \vfill
    \emph{at the} \\
    \textsc{University of Wisconsin -- Madison}\\
    \uwgraddate \\
    \vfill
    \noindent Defended on \uwdefensedate{}\\ Dissertation approved by the following members of the Final Oral Committee: \\
    \ifx\uwfoca\undefined {} 
      \else \boxfoc{\uwfoca}{\uwranka}{\uwdepa} \\
    \fi
    \ifx\uwfocb\undefined {} 
      \else \boxfoc{\uwfocb}{\uwrankb}{\uwdepb} \\
    \fi
    \ifx\uwfocc\undefined {} 
      \else \boxfoc{\uwfocc}{\uwrankc}{\uwdepc} \\
    \fi
    \ifx\uwfocd\undefined {} 
      \else \boxfoc{\uwfocd}{\uwrankd}{\uwdepd} \\
    \fi
    \ifx\uwfoce\undefined {} 
      \else \boxfoc{\uwfoce}{\uwranke}{\uwdepe} \\
    \fi
    \ifx\uwfocf\undefined {} 
      \else \boxfoc{\uwfocf}{\uwrankf}{\uwdepf} \\
    \fi
    \vfill
  \end{center}
  \clearpage
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% COPYRIGHT Page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% If you're registering copyright
\newcommand{\thecopyrightpage}{%
  \thispagestyle{empty}
  \begin{center}
    \null
    \vfill
    \copyright{} Copyright \uwauthor{} \uwgraddate{}\\
    All Rights Reserved
    \vspace{1in}
  \end{center}
}

% If you don't want to pay the copyright fee
\newcommand{\theblankcopyrightpage}{%
  \thispagestyle{empty}
  \null
  \vfill
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% UMI ABSTRACT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\theumiabstract}{%
  \clearpage

  %% The UMI abstract is not part of the document, so we skip pagination
  \savepagenumber
  \thispagestyle{empty}

  \begin{center}
    {\Large \textsc{\uwtitle}} \\
    \uwauthor \\
    Under the supervision of  \uwranka \uwfoca \\
    At the University of Wisconsin--Madison \\
  \end{center}

  \vspace{\baselineskip}

  \uwabstract

  \clearpage
  \restorepagenumber
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Other STYLE stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% myheadings is used to define custom content for the headings
% We set headings on both odd and even pages blank, as required by UW
\pagestyle{myheadings}
\markboth{}{}

% By default, the first page of a chapter has a special style, 
% so we need to explicitly set the chapter style to myheadings as well
\aliaspagestyle{chapter}{myheadings}

% Set memoir's DoubleSpacing
\DoubleSpacing
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{adjustbox}
\usepackage{xr}
\usepackage{multirow}
\usepackage{mathtools}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

%\usepackage[sorting=none]{biblatex}

%Search for an MSSM Higgs Boson and Measurement of W+b b
%with the CMS Detector at the LHC.
\settitle{A Search for Lepton Flavor Violating Decays of the Higgs Boson and a Measurement of W Boson Production using the CMS Detector at the LHC}
%\settitle{Measurement of W+ $b\bar{b}$ and a search for MSSM Higgs Bosons with the CMS Detector at the LHC}
\setauthor{Aaron Levine}
\setdepartment{Physics}
\doctors % or \masters
\setgraddate{2016}
\setdefensedate{} % or whatever format you want

%%%% Members of the Final Oral Committee (FOC)
%%%% Give name, rank, and department
%%%% 
\setfoca{ Sridhara Dasu}{Professor}{Physics} % <- Your advisor
\setfocb{Wesley Smith}{Professor}{Physics}
\setfocc{Other Member}{Professor}{Physics}
\setfocd{Other Member}{Professor}{Physics}
\setfoce{Other Member}{Professor}{Other Department}

%The places you're going to are never on the map.
%-Jim Hensen

%%%% Your abstract, used for the UMI abstract and in your front matter
\setabstract{%
%This thesis describes a standard model cross section measurement of $\Wbb$ 
%as well as a search for neutral Higgs bosons in the minimal supersymmetric 
%extension of the standard model (MSSM) decaying to tau pairs.

%The measurement of $\Wbb$ was performed
%using proton-proton
%collisions at $\sqrt{s} = 7~\mathrm{TeV}$ in a data sample collected
%with the CMS experiment at the LHC corresponding to
%an integrated luminosity of  $5.0~\mathrm{fb}^{-1}.$
%The $\mathrm{W+b\bar{b}}$
%events are selected in the $\mathrm{W}\rightarrow\mu\nu$ decay mode by requiring a
%muon with transverse momentum $p_{\mathrm{T}}>25~\mathrm{GeV}$ and pseudorapidity
%$|\eta|<2.1$, and exactly two b-tagged jets with $p_{\mathrm{T}}>25~\mathrm{GeV}$ and $|%\eta|<2.4$.
%The measured $\mathrm{W+b\bar{b}}$ production cross section in the fiducial region, %calculated at the level of final-state particles, is
%$0.53\pm 0.05~(\textrm{stat.}) \pm 0.09~(\textrm{syst.}) \pm 0.06~(\textrm{th.}) \pm %0.01~(\textrm{lum.}) ~\textrm{pb}$,
%in agreement with the standard model prediction. This measurement is a sensitive
%test of heavy quark production calculated with perturbative QCD. It also 
%serves as an important
%benchmark in new physics searches which include a 
%single isolated lepton and one or more b jets in the final state,
%as $\Wbb$ becomes an irreducible background.

%The search for neutral Higgs bosons in their decay to tau pairs is performed 
%using events recorded by the CMS experiment at the LHC
%in 2011 and 2012 at a center-of-mass energy of 7 TeV and 8 TeV respectively. 
%The dataset corresponds to an integrated luminosity of 24.6~fb$^{-1}$, 
%with 4.9~fb$^{-1}$ at 7 TeV and 19.7 fb$^{-1}$ at 8 TeV. To enhance 
%the sensitivity to neutral MSSM Higgs bosons, the search
% includes the case where the Higgs boson is produced in association 
% with a b-quark jet. No excess is observed in the tau-pair invariant-mass 
% spectrum. 
 %Exclusion limits in the MSSM parameter space of $M_A$ 
 %and tan$\beta$ in the $m_h^{\rm max}$ scenario are presented. 
 Abstract Goes Here

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%%%%%%SETLINE NUMBERS
%%\setpagewiselinenumbers
%\modulolinenumbers[1]
%\linenumbers
%%%%%%%END SETLINE NUMBERS
%% Tell the memoir class to set up lowercase roman for pagination, etc.
\frontmatter

%%%% Uncomment this to create a UMI abstract page.
%%%% If you are submitting electronically, however, this page is unnecessary.
 %\theumiabstract

% The title page
\thetitlepage

\title{A Search for Lepton Flavor Violating Decays of the Higgs Boson and a Measurement of W Boson Production using the CMS Detector at the LHC}
\author{Aaron Levine\\ Department of Physics\\University of Wisconsin-Madison}
\date{}
%\maketitle
% The copyright page, if you want to pay the fee and register copyright.
\thecopyrightpage
\cleardoublepage

% These above pages should not be counted, so we reset the counter to 1.
\setcounter{page}{1}

% An abstract may be required by your department.
\section{Abstract}
\uwabstract
\cleardoublepage

% Acknowledgements go here if you want to include them.
\section{Acknowledgements}
This is where any acknowledgements would go.
\clearpage

% Table of contents

\maxtocdepth{paragraph}
\tableofcontents* % the * means that there isn't an entry for the TOC itself
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}
\setsecnumdepth{subsection}
 \clearpage


\makeatletter
     \renewcommand*\l@figure{\@dottedtocline{1}{1em}{3.2em}}
\makeatother
 \listoffigures*  % if you have any figures
 \clearpage
 \listoftables   % if you have any tables

% Tell the memoir class to set up normal pagination, etc. for the main doc
\mainmatter
\setsecnumdepth{subsubsection}
\chapter{Theoretical Motivation}\label{theory}
\qquad In high energy particle physics, the goal is to use high energy densities to probe small distance scales and investigate properties of fundamental particles and the forces that govern them. This thesis describes the search for an exotic, lepton flavor violating, interaction between a Higgs boson, a muon, and a tau. These concepts are defined in subsequent sections of this chapter. This interaction has never been observed in nature and is prohibited by the Standard Model, the most comprehensive theory of particle interactions to date. If observed, these lepton flavor violating couplings would represent signs of a deeper theory that would significantly enhance our perception of forces and particles. This thesis also contains the measurement of W boson production and associated jets. This process involves key forces and particles of the Standard Model, and precise measurements of the process will improve understanding of the existing theory. These measurements take place at the Compact Muon Solenoid (CMS) detector using the Large Hadron Collider (LHC). 

\section{The Standard Model}\label{sm}

\qquad Our knowledge of particle interactions is summarized in a theory called the Standard Model. The theoretical framework of the Standard Model was developed over the course of the 20th century as more and more fundamental particles and forces were discovered and studied. The Standard Model is not without its flaws. It is a phenomenological theory that contains many free parameters, such as the masses of the particles, that can only be determined from experiment. It also fails to include the gravitational interactions, and thus only describes three of the four fundamental forces. The ad hoc design of the Standard Model and the lack of unification provides a strong motivation for particle physicists to search for a more profound, comprehensive theory. The current state of particles physics takes a two pronged approach, with physicists making precision measurements of the Standard Model and searching for physics beyond the Standard Model. The goal is to measure the parameters of the Standard Model while searching for the theory's extension. This thesis contains both aspects. The W+jets production cross section measurement directly tests the Standard Model while the search for lepton flavor violating Higgs couplings tests hypotheses that extend the theory.

\subsection{Elementary Particles}\label{elemparticles}
\qquad The fundamental particles in the Standard Model are summarized in Figure \ref{fig:SMParticles}. The fundamental particles consist of fermions and bosons. The fermions are particles that have half integer spin, and the bosons have integer spin. Spin is the intrinsic quantized angular momentum of a particle. The bosons mediate the fundamental forces and provide mass. They will be discussed further in Section \ref{elemforces} and Section \ref{higgstheory}. The fermions consist of the quarks, leptons, and neutrinos. 

\qquad There are three generations of quarks, with two flavors in each generation. Each quark generation consists of a quark with +2/3 of an electron charge (+2/3e) and a quark with -1/3 of an electron charge (-1/3e). Quarks also have a property known as "color." There are three possible colors for each quark: red, green, or blue. The concept of color is important for understanding the strong nuclear force, as discussed in Section \ref{elemforces}. As shown in figure ~\ref{fig:SMParticles} the masses of the quarks vary significantly from one generation to the next.

\qquad Free quarks have never been observed in nature. Only color neutral combinations of quarks have been observed. For example, a red, green, or blue quark can form a stable state with a corresponding antiquark, with an anticolor of antired, antigreen, or antiblue. This state is known as a meson. The baryons consists of three quarks, one of each color. The proton (uud), and the neutron (udd), are both baryons. Matter than is composed of quarks is called hadronic matter. At CMS, hadrons are often found in collimated streams of particles known as jets. 

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{StandardModel.pdf}
\caption{The fundamental particles of the Standard Model. Charges are expressed in units of electron charge.\cite{Agashe:2014kda} }
\label{fig:SMParticles}
\end{figure}


%Mesons consist of a quark antiquark pair, and baryons consist of three quarks, such as the proton (uud). In both cases, the charges of the quarks must sum to an integer multiple of the electron charge. Particles with non integer charges are not found by themselves in nature. It should be noted that it is simplistic to model a proton as a collection of two up quarks and a down quark. Those three quarks are known as valence quarks, which give the proton its charge and spin. In high energy collisions the "sea quarks," which are a vast number of quark antiquark pairs, dominate the model. This will be discussed further in chapter 2 ***. All matter that is made out of quarks is known as hadronic matter.

\qquad There are three generations of leptons, each with a neutrino pair. The electron is extremely light and does not decay, but the muon and the tau are heavier and have lifetimes on the order of $10^{-6}s$ and $10^{-15}s$ respectively\cite{Agashe:2014kda}. The mechanisms for lepton decay will be discussed in Section \ref{elemforces} . In the Standard Model, there is a conserved quantity known as the lepton number. Each lepton/neutrino pair, such as an $e$ and an $\nu_{e}$ each will have an electron lepton number of 1, and the corresponding antiparticle pair will have a lepton number of -1. Figure~\ref{fig:TauDecay} gives an example of a decay that conserves lepton number. In the initial state only the tau exists and the tau lepton number of the system is one while the muon and electron lepton numbers of the system are 0. The decay produces a tau neutrino which also has a tau lepton number of one along with an electron and an antielectron neutrino, which have electron lepton numbers of one and negative one, respectively. So the final state also has a tau lepton number of one. Also note that lepton number and flavor are conserved at each vertex. In the lepton flavor violating couplings studied in this thesis, a muon and a tau share a vertex, which is not allowed in the standard model. 

\begin{figure}[here]
\includegraphics[width=0.4\textwidth]{TauDecay.pdf}
\caption{Decay of the tau lepton, as mediated by the W boson. The W boson is discussed further in Section \ref{elemforces}.}
\label{fig:TauDecay}
\end{figure}

\subsection{Elementary Forces}\label{elemforces}

\begin{table}[htbp]
  \centering
  \begin{tabular}{ | l | c | r |}
    \hline
    Force & Relative Strength & Mediator \\ \hline \hline
    Strong & 1 & Gluon \\ \hline
    Electromagnetic & $10^{-3}$ & Photon \\ \hline
    Weak & $10 ^{-11}$ & W,Z Boson \\ \hline
    
  \end{tabular}
  \caption{Fundamental forces of the Standard Model\cite{Halzen:1984mc}.}
  \label{tab:FundForces}
\end{table}

\qquad The fundamental forces of the Standard Model are shown in Table~\ref{tab:FundForces}. Note that gravity is not included in the table. Gravity is not contained in the standard model and has a strength on the order of $10^{-30}$ \cite{Barger:0201058766} relative to the weak nuclear force. It plays a negligible role in high energy physics.

\qquad The theory of the electromagnetic is know as quantum electrodynamics (QED). The Electromagnetic force is mediated by the photon. The photon is a spin 0 massless particle. Two examples of electromagnetic interactions are show in figure~\ref{fig:eeScattering}. This figure displays an example of a Feynman diagram, which are pictorial representations of particle interactions that are also used to calculate the matrix elements and amplitudes of the process. Matrix elements are used to compute the cross sections, which, as described in chapter\ref{pheno}, are a measurement of the likelihood of the process occurring. The photon only interacts with particles that carry charge. 

\begin{figure}[here]
\includegraphics[width=0.4\textwidth]{eeScattering.jpg}
\caption{A photon mediating scattering between two electrons}
\label{fig:eeScattering}
\end{figure}


\qquad The weak nuclear force is mediated by the W and Z bosons. The Z boson is a neutral spin 1 particle. It decays into pairs of quarks, leptons, or neutrinos. The W boson is a charged spin 1 particle. It has the special property of changing flavors of quarks and leptons. For example, the W boson can mediate the decay of a tau to an electron. This is illustrated in figure ~\ref{fig:TauDecay}. Note that lepton number is still conserved in these types of interactions.  

\qquad The theory of the strong nuclear force is known as quantum chromodynamics (QCD). The strong nuclear force is mediated by the gluon. Each gluon is a color doublet, with a corresponding color and anticolor. For example, a gluon could be red and antigreen, or blue and antired, et cetera. Gluons only interact with particles that share one of their color charges. Therefore, the quarks are the only particles involved in strong interactions. Virtual gluons can self interact which increases the strength of the color charge surrounding a quark. At small distance scales the virtual gluon cloud is penetrated and the effective color charge decreases. This effect is known as asymptotic freedom. \cite{Halzen:1984mc} At larger distances, as a quark antiquark pair move apart from each other, the increase in potential energy allows new quark antiquark pairs to be created from the vacuum. The new quarks will be bound to the initial quarks by the strong nuclear force, which is why free quarks have never been observed. 
\qquad The coupling constant for QCD, $\alpha_{s}$, is energy dependent and scales as $\alpha_{s}(Q^{2}) \propto 1/ln(\frac{Q^{2}}{\Lambda_{QCD}^{2}})$. Here $Q^{2}$ represents the momentum transfer of the process and $\Lambda_{QCD}$ is a constant, referred to as the QCD scale, with a measured value of 214 MeV\cite{Agashe:2014kda}. At the TeV scale collision energies of the Large Hadron Collider, $\alpha_{s}$ is small and interactions are modelled using perturbative QCD (pQCD). Leading order terms that depend on $\alpha_{s}$ and next to leading order terms that depend on $\alpha_{s}^{2}$ dominant the computation and higher order terms can be neglected.

\qquad As mentioned in chapter \ref{wboson} both the strong force and the weak force play important roles in the production of W bosons and associated jets. The strong force governs quark-gluon interactions and jet formation, while the weak force is responsible for the W boson couplings to initial start quarks and final state muons. Thus, a precision measurement of W+jets production is an powerful channel to evaluate the accuracy of the Standard Model.



\subsection{The Higgs Boson}\label{higgstheory}
\qquad In classical physics, the equations of motion of a system are governed by the Lagrangian. The Lagrangian is defined as $L = T - V$ where $T$ is the kinetic energy and $V$ is the potential energy. In the Standard Model, we can also define a Lagrangian that governs all particle interactions\cite{Halzen:1984mc} However, when mass terms for W and Z bosons are added to the Lagrangian, the Standard Model breaks down. Loops formed by W and Z bosons contribute infinities to Standard Model calculations that cannot be removed. This means that the Standard Model becomes unrenormalizable. 

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{HiggsPotential.png}
\caption{The potential of the Higgs Field. Note the nonzero minima.}
\label{fig:HiggsPotential}
\end{figure}

\qquad To resolve this, we introduce a field with a potential shown in figure ~\ref{fig:HiggsPotential}. This potential has a minimum that is not at the origin of the coordinate system. We can break the symmetry by shifting our reference point to the minimum of the potential and expanding for small deviations about the minimum. When this shift is introduced to the Lagrangian, it results in mass terms appearing for the W and Z bosons, the quarks and leptons, and a mass term for the particle associated with the field itself. That particle is known as the Higgs Boson. In addition to providing the theoretical framework to add mass terms to the Lagrangian, the Higgs Boson couples to every massive particle in the Standard Model. The couplings of the Higgs to the W and Z bosons cancel out the infinities mentioned earlier.\cite{Halzen:1984mc} Thus, the field that naturally gives rise to masses in the Standard Model also cancels out the divergences that prevented us from simply placing mass terms in the Lagrangian to begin with. A Higgs Boson with a mass of 125 GeV was discovered at CERN on July 4 2012. \cite{Agashe:2014kda}
 

\section{Beyond the Standard Model}\label{BSM}

\qquad As mentioned in Chapter \ref{theory} Standard Model requires many free parameters determined by experiment and fails to unify gravity with the other four fundamental forces. Additionally, it fails to account for neutrino oscillations\cite{Fukuda:1998mi}\cite{Ahmad:2001an}\cite{Ahmad:2002jz} and it doesn't address the hierarchy problem. \cite{ArkaniHamed:1998rs} A more fundamental theory must exist, and the recently discovered Higgs boson provides a rich environment for probing the existence of such a theory. Many proposed theories such as Randall-Sundrum models \cite{Randall:1999ee} or Two Higgs Doublet models \cite{Branco:2011iw} predict a Higgs boson with couplings that violate lepton flavor conservation. The strength of Higgs couplings are proportional to the masses of the particles involved, so the most logical place to start a search for lepton flavor violation would be a Higgs boson coupling directly to the two heaviest leptons: a muon and a tau.

\qquad There have been no direct searches for $H \rightarrow \mu\tau$ prior to the result contained in this dissertation. Null searches for $\tau \rightarrow \mu\gamma$ constrain the branching fraction for $H \rightarrow \mu\tau$ to $\mathcal{O}(10\%)$.\cite{Harnik:2012pb}

\qquad Lepton flavor violating couplings may explain a discrepancy in the anomalous magnetic moment of the muon. The magnetic moment is a quantity defined for a current loop that describes the torque the current loop experiences in a magnetic field. Muons are point particles, so according to classical electrodynamics they lack a magnetic moment. However, in QED, loop interactions will effectively generate a magnetic moment, known as the anomalous magnetic moment of the muon. The current measured value differs from the expected standard model value by $2.87 \times 10^{-9}$, a significance of $3.6 \sigma$ \cite{Bennett:2004pv}\cite{Agashe:2014kda}. Loop corrections, as shown in Figure\ref{fig:mutauloop} from a Higgs coupling to a muon and a tau could resolve this discrepancy \cite{Harnik:2012pb}.

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{mutauloop.jpg}
\caption{Loop contribution of lepton flavor violating couplings between muons and taus to the anomalous magnetic moment of the muon.}
\label{fig:mutauloop}
\end{figure}

\chapter{Collider Phenomenology}\label{pheno}
Now that the underlying physics has been described in Chapter \ref{theory}, the question remains: how exactly are W+Jets and lepton flavor violating Higgs events produced and studied? Before proceeding further, it is necessary to define some basic terms of collider physics. The cross section of a particle interaction is an effective area that gives a sense of the likelihood of the interaction. In collider physics, cross sections are measured in barns (b), where $1b = 10^{-24}cm^{2}$. The luminosity is defined as the rate of observed events divided by the cross section. The integrated luminosity is computed by integrating the luminosity with respect to time. Integrated luminosity is used to define how much total data a collider has supplied. These terms will be used for describing proton proton collisions, W boson production, and Higgs boson production in the coming sections of this chapter.

\section{Proton-Proton Collisions}\label{ppcoll}
\qquad The Large Hadron Collider (LHC), which will be discussed further in Chapter \ref{experiment}, is a proton-proton collider. The proton, as mentioned in Chapter \ref{theory}, is considered to be the bound state of three quarks: two up quarks and a down quark. However, proton-proton collisions cannot simply be thought of as six up and down quarks interacting. Inside the proton, massive amounts of quark and antiquark pairs pop in and out of existence. At the high energies and short distance scales probed by the LHC, these "sea quarks" play a dominant role in proton proton collisions. The gluons that bind elements of the quark/antiquark sea also play a large role in collisions. In fact, these gluons carry about 50$\%$ of the proton's momentum\cite{Halzen:1984mc}. So when two protons collide at the LHC, it is effectively a collision between two clouds of gluons and quarks.These collisions can be studied via the parton model. This model defines the protons as collections of point particles (partons) carrying a fraction $x$ of the hadron's momentum. The distribution of $x$ depends on the momentum scale $Q^{2}$ that is probed. 

\qquad When these clouds of gluons and quarks collide, most of the collisions involve a small amount of momentum transfer between the particles involved. These are known as "soft" scattering. The important processes, such as W boson or Higgs boson production, require a "hard" scattering event. These types of events seldom happen more than once each time the clouds of gluons and quarks intersect. Therefore, for each interesting hard scattering event there will be many soft scattering events occurring at the same time. The soft scattering events are referred to as the "underlying event."

\qquad In addition to the hard scattering process of interest, there will be extra proton-proton interactions in each event which produce additional particles. These additional hard scattering interactions are referred to as "pileup". The additional particles produced   threaten to cloud the hard scattering process at the primary vertex. Methods of vetoing and subtracting pileup contributions to the event are discussed in section \ref{eventreco}. 

\qquad As quarks and gluons move apart after the collision, the increase in potential energy from the strong interaction produces a stream of collimated hadrons, known as a jet. Jet formation is shown in Figure \ref{fig:JetFormation}. First, energetic quarks radiate gluons, which split into quarks. These quarks may still be energetic enough to radiate gluons, and the process continues. This is known as parton showering. Detailed simulations are described in chaper \ref{eventsim}. After the conclusion of parton showering, hadronization occurs. QCD confinement requires that the quarks and gluons are naturally grouped into colorless clusters. These clusters then separate into groups of hadrons, which is known as hadronization. The identification of jets is discussed in Chapter \ref{eventreco}.

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{jetformation.jpg}
\caption{Diagram of jet formation occurring after a hard scatter event. First quarks and gluons are radiated in parton showering. Then they combine into colorless cluster before condensing into the hadrons that make up jets.}
\label{fig:JetFormation}
\end{figure}



\section{W Boson Production: Mention prior results}\label{wboson}
\qquad W bosons are produced by deep inelastic scattering between partons, as show in Figure \ref{fig:WFormation}. The cross section of this process depends on the parton distribution functions. Examples of CTEQ6 parton distribution functions are show in Figure \ref{fig:cteq6PDF.jpg}\cite{Pumplin:2002vw}. These parton distribution functions are used in PYTHIA (chapter \ref{eventsim}).

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{WFormation.jpg}
\caption{Diagram of W Boson production. The function $F_{1}$ and $F_{2}$ are the parton distribution functions of the incoming protons.}
\label{fig:WFormation}
\end{figure}

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{cteq6PDF.jpg}
\caption{Parton distribution functions in the CTEQ6 scheme\cite{Pumplin:2002vw}. As the energy $Q$ of the collision increases, the quarks involved carry less and less of the proton's momentum and the applicability of pQCD increases.}
\label{fig:cteq6PDF}
\end{figure}

\qquad W bosons decay to leptons and quarks at equal rates. The W may decay to an up/down quark pair, a charm/strange quark pair, or a lepton/lepton neutrino pair. The presence of the muon neutrino in the final state is necessary to conserve lepton flavor in the standard model, as discussed in Chapter \ref{theory}.  The decay to a bottom/top quark pair is suppressed because of the high mass of the top quark. Each quark has three flavors, and there are three total leptons, so ultimatly W decay has six hadronic final states and three leptonic final states. This means that W bosons decay to hadrons approximately 67$\%$ of the time and decay to leptons about $33\%$ of the time. As discussed in Chapter \ref{experiment} and Chapter \ref{eventreco}, due to CMS's ability to reconstruct muons, we look for W bosons decaying to a muon and a muon neutrino. Because of lepton universality, the branching fraction of $W \rightarrow \mu\nu_{\mu}$ is about 11$\%$. 

\qquad W boson production is studied based on the number of jets produced in association with the W boson. An example of a single radiated jet is show in Figure \ref{fig:WOneJet}. The cross section for W boson from two partons scattering is given by equation \ref{eq:wprod} \cite{Barger:0201058766}. Here, $V_{ud}$ is a matrix element that defines the probability for up-down quark transition, $G_{F}$ is a fundamental constant, $M_{W}$ is the mass of the W boson, and $\hat{s}$ is the momentum of the diquark system. The hats on $\hat{s}$ and $\hat{\sigma}$ indicate that these values apply to one parton scatting off of another parton. To calculate the full cross section of W production we must integrate over the parton distribution functions of the quarks involved.

\begin{equation} \label{eq:wprod}
\hat{\sigma}(u d \rightarrow W) = 2\pi |V_{ud}|^{2}\frac{G_{F}}{\sqrt{2}}M_{W}^{2}\delta(\hat{s} - M_{W}^{2})
\end{equation}

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{WOneJet.jpg}
\caption{Example of the production of a W plus one jet event.}
\label{fig:WOneJet}
\end{figure}

Previous results from CMS measured at 7 TeV center of mass collisions\cite{Khachatryan:2014uva} are show in Figure \ref{fig:wjets7TeV}. 

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{wjets7TeV.jpg}
\caption{W+jets production at CMS in 2011. Cross sections are show in units of picobarns. The left plot shows exclusive jet binned (= NJets) results and the right plot shows inclusive jet binned ($\geq$ NJets) results. Comparisons between theoretical predictions and data are shown in the ratio plots. Agreement is within statistical uncertainty. }
\label{fig:wjets7TeV}
\end{figure}


\section{Higgs Boson Production}\label{higgspheno}
\qquad As discussed in Chapter \ref{theory}, Higgs boson couplings are mass dependent. The more massive the particle, the more likely it will couple to the Higgs. Top quarks, with a mass of 172 GeV, are the heaviest standard model particle. As a result, the dominant method of Higgs production is when two energetic gluons fuse together via create a top quark loop, as shown in Figure \ref{fig:ggfHiggs}. This is called gluon-gluon fusion.

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{ggfHiggs.jpg}
\caption{Higgs production via gluon gluon fusion.}
\label{fig:ggfHiggs}
\end{figure}


\qquad Vector boson fusion is the dominant mechanism of two jet Higgs boson production. It is shown in Figure \ref{fig:vbfHiggs} Because of conservation of color, the two final state quarks must be the same color as their corresponding initial state quarks. This will force the jets produced by the final state quarks apart at a wide angle. A graphic of all the Higgs production channels is shown in Figure \ref{fig:higgsproduction}\cite{Dittmaier:2011ti}.

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{vbfHiggs.png}
\caption{Higgs production via vector boson fusion.}
\label{fig:vbfHiggs}
\end{figure}

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{higgsproduction.jpg}
\caption{Higgs production cross sections\cite{Dittmaier:2011ti}. At a mass of 125 GeV, the two largest production modes are gluon gluon fusion and vector boson fusion.}
\label{fig:higgsproduction}
\end{figure}

\qquad There is no known Higgs branching ratio to guide this search. This is the first direct measurement of $H \rightarrow \mu \tau$. The kinematics of this search are similar to the kinematics $H \rightarrow \tau\tau$ search carried out at CMS \cite{Chatrchyan:2012xdj}. As discussed in chapter ~\ref{taus}, tau leptons are detected at CMS via their hadronic decay mode ($\tau_{h}$) or their leptonic decay modes ($\tau_{e}, \tau_{\mu}$). Therefore, the final state objects, a muon and a tau, are exactly the same between $H \rightarrow \mu \tau$ and the $H \rightarrow \tau_{mu} \tau$ channel of $H \rightarrow \tau\tau$, making $H \rightarrow \tau\tau$ a major background of the search. A major difference between $H \rightarrow \tau_{mu} \tau$ and $H \rightarrow \mu \tau$ is the distribution of missing transverse energy (MET) in the event. MET, which is discussed further in chaper ~\ref{met}, arises from neutrinos that CMS cannot detect. As shown in figure ~\ref{fig:TauDecay}, neutrinos are always associated with tau decays. The $H \rightarrow \tau_{mu} \tau$ channel will contain a muon neutrino associated with the muonic decay of the tau, but $H \rightarrow \mu \tau$ contains no such neutrino. The only neutrinos will be associated with the tau decay. The MET distribution will be used to define the signal region in chapter 6. A graphic of Higgs boson decay probabilities is shown in Figure \ref{fig:higgsBR}\cite{Heinemeyer:2013tqa}

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{higgsBR.jpg}
\caption{Higgs decay branching ratios\cite{Heinemeyer:2013tqa}. The mass of the Standard Model Higgs is 125 GeV. }
\label{fig:higgsBR}
\end{figure}

\section{Kinematics Definitions}\label{kindef}
\qquad Before proceeding further it is necessary to define relevant kinematic variables. The protons are accelerated up to almost the speed of light, so a relativisitic treatment must be used to study the collisions.   In special relativity, the energy of the system, $E$, is defined as $E^{2} = m^{2}+p^{2}$. Here the speed of light, $c$, is set to 1, in accordance with natural units. The energy momentum 4-vector is defined as $ \hat{P} = (E, \vec{p})$, and the dot product is defined such that $\vec{P} \dot \vec{P} = E^{2}-p^{2}$, which is the lorentz invariant mass of the particle. The square of the sum of four momentum vectors gives the invariant mass of a system of particles. Lorentz invariant quantities are useful because they are frame of reference independent. 

\qquad For two colliding particles, $p_{1}$ and $p_{2}$ we can define a quantity: $s = (p_{1}^2+p_{2}^2)$, which is the Lorentz invariant square of the total center of mass energy of the event.

\qquad The rapidity $y$ of a particle is defined as: $y = \frac{1}{2}ln(\frac{E+p_{z}}{E-p_{z}}$, where $p_{z}$ is the component of the momentum parallel to the beam axis. The rapidity gap between two particles, $\Delta y_{12}$, is lorentz invariant. The pseudorapidity $\eta$ is defined as : $\eta = \frac{1}{2}ln(\frac{p+p_{z}}{p-p_{z}}$. This can be expressed in terms of polar angle (Section \ref{cms}) as $\eta = ln(cot(\theta /2))$. The pseudorapidity is equal to the rapidity if the rest mass is 0. At high energy collisions at the LHC, $E \gg m$ and $y \approx \eta$.

\chapter{Experimental Design: The Headings below are self explanatory}\label{experiment}

\section{LHC}\label{lhc}
1e11 protons per bunch, 2835 bunches/beam, 1e34 lumi (at 7 tev, check numbers!!)
check numbers: 4e7 hz bx, 1e9 Hz collisions
1e-13 event selection

transverse emittance ($\epsilon$): smallest opening you can squeeze the beam through
									measurement of the parallelism of a beam
amplitude function $\beta$, $\beta = \pi\sigma^{2}/\epsilon$
where $\sigma$ is cross sectional size of bunch

$\beta^{*}$ is distance from focus point that beam is twice as wide as the focus point

8 TeV (7e33 lumi, f=20e6 Hz, N < 1.7e11 p/bunch, $\epsilon$ < 1.75 um, $\beta^{*} = 0.60m$

Booster to PS to LINAC2 to SPS to LHC

\section{CMS}\label{cms}
\subsection{Overview}
\subsection{Tracker}\label{tracker}
silicon sensors (strips and pixels), measure momenta, identify vertex
pixel: n+ in n bulk, 100x150 mum^2
at r = 4.4, 60 MHz/cm2 at peak lhc lumi 1e34
3e14 n/cm2/yr
10-4 occupancy

18m and 48m barrel pixels
66 million pixels
10 million strips
pixels seed tracking, vertexing, 95\% efficiency
strip tracker: design occupancy 1-2\%
outer cell size 20x100-200 um
inner cell sizer 10X80 um

petals: intermediate structure
400 pieces makes one petal, needed 288 total

readout via optical fibers

electron hole pair pairs generated by particles are separated by e field and drift to electrodes

strips: wire bonds, multiplxer
pixels:SiN strips, readout chips, pixel sensor, bump bonding, highdensity interconnect, token bit manager
strips: synchronous, pixel: asynchronous

pixel detector occupancy at least one order of magnitude smaller than strips

talk about distribution of material with respect to eta

barrel pixels can move over time
movements checked on runs > 20k events
significant movement-> alignment recomputed on 100k event run

phase II upgrade (from 2014 slides) more radiation tolerant, finer granularity, lower mass, forward to eta4, l1 trigger capability
\subsection{ECAL}\label{ecal}
barrle, endcap, preshower

lead tungstate crystals

8.28 g/cm^3, 0.85 radiation length, 2.19 moliere radius, 440 nm wavelength peak, <10 fast decay constant, 100 light yield per MeV

em shower generated by electron/photon, charged particles produce scintialltion light isotropically, 
proportional to particle energy, detected by photodetectors with internal amplification (EB- avalanche photodiodes), (EE- Vacuum PhotoTriodes)

PbWO4 crystals transparent to entire scintillation spectrum before irradiation

barrel: eta < 1.48
	36 supermodules: 1700 crystals (1 supermodule = 4 modules)
	61200 crystals total, 17 shapes
	2.2x2.2x23 ~26 radiation lengths
endcaps: 1.48 < eta < 3.0
		 4 disc (2 per endcap) 3662 crystals (mostly in 5x5 supercrystals)
		 14648 crystals total of 1 shape
		 3.0 x 3.0 x 22 ~25 Xo
preshower 1.65 < eta < 2.65
		 4 planes (2 per endcap) 1072 silicon sensors
		 1 sensor = 6.3 x 6.3 x 0.032 cm^3, 32 strips, 137216 strips total
		 2Xo + 1Xo of Pb with Si strips
		 1.90 x 61 mm2 x-y view
		 
front end electronic: mgpa with 3 separate gains
- 1 mgpa + 1 adc per crystal
fenix chip stores digital signal from multiple crystals until level 1 trigger signal received
another fenix chip sums energy in group of crystals (5x5 in EB, 5 in EE, tpg sent to trigger electronics)
sum energy for trigger at 40 MHz, crystal data sent at 100 kHz
multi gain pre amplifier 

energy resolution 
$\frac{\sigma_{E}}{E} = \frac{A}{\sqrt{E}} \oplus \frac{B}{E} \oplus C$
A = stochastic term (energy fluctuations)
B = noise term (quantum electronic/ pu noise)
C = constant term (contruction, stability, uniformity)

A = 2.8\%
B = 0.128
C = 0.3

energy resolution based on 3x3 arrarys of barrel crystals

L1: 2012, 5x5 towers for egamma

l1 eg trigger 2012: 
5x5 crystals in barrel
4 l1 eg candidates per region (4x4 towers)
keep 4 candidates with highest et in ECAL
fine grain veto: 90\% tower Et within 2 adjacent strips
H/E < 5\%
isolated stream: sum of 5 adjacent towers < 3.5 GeV,8 neighbor towers pass FG and H/E selections
non isolated stream

laser calibrations: 447 nm, averaged over 40 minutes for each crystal

preshower: 6.3 x 6.3 cm, 1.9 mm strips Si sensors
vetoes pi0 faking single photons by resolving closely spaced incident photons

\subsection{HCAL}\label{hcal}
outer, barrle, endcap, forward, castor, zdc

incident hadron generates em shower in brass absorber, scintillation light produced in plastic,
transported to heavy brass absorber

copper plates (70\% copper, 30\% zinc)
copper plates "interleaved" with plastic scintillators with wavelength shifting fibers
light channeled using clear fibers to photodetectors located at end of barrel
HF: radiation hardness important, stell plates with cherenkov producing quartz fibers

barrel: eta < 1.3, 36 wedges ( 18 +/-)
14 layers of brass: 10 interaction lengths
16 megatildes, 16 eta and 4 phi division per wedge

endcaps: 1.3 < eta < 3.0, 36 wedges per endcap
17 layers of brass: 10 interaction lengths
17 megatile layers: 12 eta and 1-2 phi division per wedge
2-3 high eta longitudinal segments

forward: 3.0 < eta < 5.0, 18 wedges per end
steel plates 5mm thick, 165 cm 10 interaction lengths
grid of holes 5mm apart
1mm diameter fibers (600 um quartz core + cladding + buffer)
half are 165 cm long
other half start after a depth of 22 cm

castor:
5.2 < eta < 6.6 on - side of cms 
14.38 from interaction point, layers of tungsten plates interleaved with fused silican quartz plates
light readout via pmts
em (20.1 x0, .77lambda), hadronic (9.24)

zdc:
heavy ion physics , eta > 8.3
tungsten plates and quartz fibers

readout: hybrid photo-detectors, designed to operate in high magnetic field
proximity focusing with 3.5 mm gap, with e field || to B field
gain of 2k, linear response over large dynamic range from mips up t o3 TeV hadron showers

charge integrator and encoder (QIE) ADC chips digitze HPD/PMT signals
QIE has 4 capacitors, connected to input by 25 ns time intervals
ever 25 ns integrated charge from capacitors is sent to HCAL trigger boards

about 90\% energy response above 20 GeV track momentum



HF lumi measurement
\subsection{Muon System}\label{muonsys}
dt's and csc's: positions measurement
rpc's: redundant triggering
0< eta < 1.2: 5 wheels, 4 stations, instrumented with DT's and RPC's
endcap: 0.9 < eta < 2.4: 3 discs, 4 stations, instrumented with csc's and rpc's

gas detectors to cover a large surface area
amplify signal within gas volume

drift tubes
250 (or 240?) chambers in barrel
drift time measurement to few ns gives 250 mum accuracy

12 layers per chamber

argon(85) + co2(15)

csc's: 540 in edncaps, cathode strips gives 200 um accuracy
6 layers
precision phi from cathode strips, rougher r from anode wires

rpc's: 480 in barrel, 576 in endcap
double gap, each 2mm 9.6

detectors located beyond 10 interaction lengths, little punchtrough of hadrons

punchthrough rate dominated by particles made in hadronic showers

muons come to rest before 4th muon station if p<5.2 gev (pt < 1.9 at eta=2)

muon trigger efficiency: dips due to crack between dt wheels 0 and pm1 in eta 0.2-0.3
eta > 1.2 assymmetry due to csc non operational chambesr ***

spatial resolution: 80-120 um in dt's 40-150 um in csc, 0.8-1.2 cm in rpc's

efficiency 95-98\%
\subsection{Trigger}\label{trigger}

reduce 40 MHz to 1 kHz
l1 trigger turns 40 MHz into 100 kHz
HLT turns 100 kHz into 1 kHz

fast readout from detector
FPGA and ASIC hardware 

include diagram of L1 trigger

HF, HCAL, ECAL send tpgs to RCT
RCT sends e/gamma, region Et to global calo trigger
4 iso e/gamma, 4 e/gamma, 4+4 jet, 4 tau, Et, Ht
RPC sends to pattern comparator
DT to DT local to DT trackfind/ CSC trackfind
CSC to CSC local, CSC trackfinder
RPC pattern comparator, DT trackfinder, CSC trackfind to GMT
GMT sends 4mu to GT


DT and CSC: DTTF and CSCTF build muon candidates from tracks
	each candidate assigned eta, phi, pt, quality
	select 4 DT and 4 CSC candidates

HCAL primitives
	ET in each tower
	
e/gamma candidates: id based on shower shape, isolation from ECAL and H/E
	4 isolated and 4 non-isolated e/gamma candidates
	
jet candidates:
	calorimeter regions (4x4 towers)
	sum et of 3x3 regions
	4 central jets (eta < 3), 4 forward jets (eta > 3)
	4 tau jets (eta < 3)
	
Et, Ht, MET MHT, computed from all regions above threshold

L1 global trigger reads candidates from muon and calo triggers
defines up to 128 algorithms

L1 Trigger upgrade
replace L1 GCT with Stage 1 Layer 2
dedicated trigger for taus
*include performance plot*
discuss tau veto bit, 

DAQ:
detector readout
event builder
HLT farm, cluster filesystem

HLT
200 ms average time to make a decision
400 Hz average output rate
runs on farm of commercial computers
13,000 cpu cores, 20000 processes

L2 standalone muons
L3 global and tracker muons
tracker based isolation

photons: ecal superclusters
calorimeter based id and isolation: tracker id and isolation

taus: particle flow reconstruction

jets, MET, HT: calorimetric jets and MET, particle flow based jets and MET

bjets: jets, full tracking, secondary vertex reconstruction

collects streams for physics analysis, trigger studies, calibration workflows

\chapter{Event Simulation}\label{eventsim}
\qquad Particle interactions at CMS are computationally intensive to model. The strong nuclear force plays a dominant role in proton-antiproton collisions, but calculations involving QCD depend on large numbers of terms 
that define interactions between many quarks and gluons. At short distances, on the order of a femtometer, we can define the momentum scale $Q$ to be much greater than $\Lambda_{QCD}$, as defined in chapter \ref{fundforces}  This means that the effects of QCD can be calculated perturbatively (pQCD), which means that high order terms can be neglected and the calculations can be simplified. However, there are large amounts of soft radiation at $\Lambda_{QCD}$, as explained in chapter \ref{ppcoll}, which necessitates the use of computational software.
\qquad The interactions of the collision products with the the detector also need to be modelled via simulation. Accurate models of physical processes at CMS are vital for testing existing theories and searching for new ones, so accurate modelling of these processes is very important for CMS and for particle physics in general.
   
\section{Monte Carlo Event Generation}\label{mcgen}
\qquad Physical processes at CMS are simulated using a class of software called Monte Carlo generators. These programs are named after the location of the famous casino because Monte Carlo software leans heavily on random number generation to simulate the kinematic distribution and decay chains of the event products. When using Monte Carlo software to simulate collisions, the user must specify the center of mass energy, the initial colliding particles, and the desired final products. Additional parameters can be defined by the user, such as the hadronization scale discussed in chapter \ref{hadronization}.  The three main components of Monte Carlo simulation are matrix element computation, parton showering, and hadronization. 


\subsection{Matrix Elements}\label{matrix}

\qquad  Once the initial and final state particles are specified, a series of Feynman diagrams are created. From the matrix elements discussed in chapter \ref{theory}, production amplitudes are computed for the process.
%By using Feynman rules as discussed in chapter \ref{theory} and averaging over helicity and color, production amplitudes are computed for the process. 
However, this calculation provides only a very basic picture of the event and neglects soft radiation at the pQCD scale. 
%For example, MADGRAPH\cite{Alwall:2014hca} models a proton as a collection of up, down, charm, and strange quarks, along with their antiparticle partners and gluons. In order to accurately compare data with theoretical models, more sophisticated models of the event are needed.
\subsection{Parton Showering}\label{partonshower}
\qquad As discussed in chapter \ref{pheno}, in high energy collisions protons can be modeled as collections of partons where the partons are pointlike particles carrying a particular fraction of the proton's momentum. Parton distribution functions, as discussed in chapter \ref{pheno}, provide a model of how the protons will interact in a collision. 

\qquad After the proton-proton collisions, Sudakov Form Factors\cite{Agashe:2014kda} are computed, which represent the probablity of a parton splitting into multiple partons. A low momentum bound for splitting is defined, and all partons above this threshold are randomly split in accordance with the probability of splitting. Color is properly accounted for at each vertex. Parton showers simulate QCD radiation emitted by quarks in the form of gluons, or a gluon splitting into two quarks.

\qquad At this point it is necessary to reconcile the matrix element computation, which represents high energy hard scattering, with parton showers, which model soft radiation. Two methods are available. The matrix element and parton shower method (ME+PS) and the next to leading order and parton shower method (NLO+PS)\cite{Agashe:2014kda}. In the ME+PS method, matrix elements are computed for the fundamental process with the addition of $n$ partons. The additional partons are required to be separated by a specified transverse momentum threshold. The momentum threshold is chosen to be at the upper limit of pQCD. In this way, the event can be computed accurately at large angle via matrix element methods, and then parton showering algorithms can be applied to the additional partons in the event. The ME+PS method is good for simulating events with many hard jets that are well separated. These kind of jets are simulated much better with tree level computations rather than lower energy pQCD parton showering. The next to leading order and parton shower method (NLO+PS) extends to parton shower method to next to leading order to QCD. 

\subsection{Hadronization}\label{hadronization}
 
\qquad After parton showering, the event consists of the hard final products and many soft partons, as defined in chapter \ref{ppcoll}. At this point, the partons must transform into color singlet final state hadrons. One way to the this is the Lund string model\cite{Barger:020105876}. In this model, quark and anti-quark pairs are connected by color "strings" with a potential 
$V(r) = \kappa r $, where $r$ refers to the distance between the quarks and $\kappa$ is a dimensionless constant that defines the strength of the potential. Since the potential is directly proportional to the distance between the quark pairs, the energy of the system increases as the quarks move further apart. Eventually, the energy of the system is enough to generate an additional quark/anti-quark pair, which effectively breaks the string into two separate string, as shown in figure~\ref{fig:lund}.The $p_{T}$ of the quark or anti-quark is  
$<p^{2}_{T}> = \kappa / \pi$ and the Lund fragmentation function\cite{Agashe:2014kda} defines the fraction of the longitudinal momentum of the endpoint particle that is imparted to its recently produced neighbor. In this fashion, the kinematic variables of the produced hadrons are known, and the shower continues until an energy scale cutoff is reached.

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{lundstring.png}
\caption{An illustration of the Lund string model. As the quark/anti-quark pair move further apart, the increase in potential energy creates an additional quark/anti-quark pair.}
\label{fig:lund}
\end{figure}


%The second method, the cluster model, is based on the fact that at any energy scale clusters of color singlet partons appear with an invariant mass distribution that is independant of the starting hadronization energy scale. 

%\qquad In the cluster model, all gluons are forced to split into quark-antiquark pairs following hadronization. This results in a series of color singlet quark-antiquark clusters. Clusters above a given threshold are required to break up until all clusters are below the cutoff value. A probablity is defined for low energy clusters to decay to one hadron. The remaining clusters are treated as excited mesons and are allowed to decay according to flavor and spin considerations. By decaying some clusters to one hadron, the cluster model improves the modeling of hadrons that carry most of the momentum of their parent jets.

\subsection{Monte Carlo Generator Software}\label{mcsoftware}

\qquad A variety of different Monte Carlo generators are used at CMS. MADGRAPH \cite{Alwall:2014hca} is used to compute matrix elements. Next to leading order (NLO) matrix elements can be computed with the aMC@NLO\cite{Alwall:2014hca} version of MADGRAPH or with POWHEG\cite{Alioli:2010xd, Frixione:2007vw, Nason:2004rx}. NLO calculations are vital for accurately depicting physical processes such as W+Jets or Z+Jets. These calculations include quark and gluon loops that complement the fundamental hard scattering process. However, MADGRAPH and POWHEG do not include parton showering and hadronization, which are necessary for accurate modelling of proton-proton collisions and jet formation, as discussed in chapter \ref{ppcoll}. The output of the matrix element generators are piped into PYTHIA, which models parton showers and hadronization using the Lund String Model. While PYTHIA is a powerful tool for calculating parton showering and hadronization, it is only a leading order (LO) generator, so it must receive matrix element results MADGRAPH or POWHEG to give results at the desired degree of precision. After hadronization, some heavy states may still need to decay. The $\tau$ lepton is too short lived to be directly observed in the detector, so any Monte Carlo simulation must decay the $\tau$ further. 
TAUOLA \cite{Was:2011tv} is interfaced with PYTHIA to provide an accurate view of $\tau$ decay by taking into account $\tau$ helicity and polarization. The Monte Carlo for FeMtobarn (MCFM) program \cite{Campbell:1999ah}\cite{Campbell:2011bn}\cite{Campbell:2015qma} is used to calculate the expected cross sections of the Monte Carlo simulation. 

%\subsection{Monte Carlo Samples}\label{mcsamples}
%\subsubsection{LFV Higgs}\label{mclfv}
%\begin{table}[hbtp]
% \begin{center}
% \caption{Monte Carlo simulations used for 8 TeV $H \rightarrow \mu\tau$.}
%  \label{tab:8TeVLFV}
%  \vspace{0.1in}
%  \begin{tabular}{|l|l|l|} \hline
%                                                   & Description &  Generator & $\sigma$(pb)     \\ \hline
%LFV Higgs Signal (GGF)          & Pythia8             &  19.6             \\ \hline
%LFV Higgs Signal (VBF)          & Pythia8             &  1.58             \\ \hline
%SM Higgs Signal (GGF)           & Pythia6+Tauola             &  19.6             \\ \hline
%SM Higgs Signal (VBF)           & Pythia6+Tauola             &  1.58             \\ \hline
%$W \rightarrow l\nu + jets$          & Madgraph + Pythia6             &  37509             \\ \hline
%$qq \rightarrow l^{+}l^{-} + jets$   & Madgraph + Pythia6             &  19.6             \\ \hline
%LFV Higgs Signal (GGF)          & Pythia8             &  19.6             \\ \hline
%LFV Higgs Signal (GGF)          & Pythia8             &  19.6             \\ \hline
%LFV Higgs Signal (GGF)          & Pythia8             &  19.6             \\ \hline

%Selection(lepton1), Selection(lepton2)              & Region I              &  Region II             \\ \hline
%  \end{tabular}
% \end{center}
%\end{table}


\section{Detector Simulation}\label{detectorsim}
\qquad After the simulation of the physical process, complete with parton showering and hadronization, it is necessary to model the interactions of the finale state particles with the CMS detector. This is done using GEANT4\cite{Allison:2006ve}. First, an accurate model of the CMS detector must be built in GEANT4, defining both the geometry and material components of the detector. The simulation is then carried out in two steps: tracking and detector response. The tracking step simulates the passage of particles through matter, modelling the energy lost based on the particles and the detector material. The next step is to model the detector response. This will simulate the signal that each event will create. After the the GEANT4 simulation has completed, the output is converted to the same software format as the actual data and then reconstructed with the same algorithms discussed in chapter \ref{eventreco}. The fully simulated events will retain all of the original Monte Carlo scattering information, so we can now understand what a particular physical process will look like from the point of view of the CMS detector. This allows us to study and improve the reconstruction of data, as discussed in chapter \ref{eventreco}.

\chapter{Event Reconstruction}\label{eventreco}

\qquad Studying physical processes requires reconstructing the particles in each event from the detector response. This is accomplished via the particle flow algorithm, which is discussed in Section \ref{pflow}. Specific applications to physics objects are discussed in subsequent sections of this chapter. In particular, the important objects for $H \rightarrow \mu\tau$ are muons, electrons, hadronic tau deposits, jets, and missing energy. The important objects for W+Jets are muons, jets, and missing energy.
\section{Particle Flow Overview}\label{pflow}
\qquad As discussed in Section \ref{cms}, the CMS detector is divided into many layers, each of which is responsible for measuring a unique part of an event. The detector response from each layer can be thought of as a building block for an event. Particle flow uses a series of algorithms to link these blocks to reconstruct the particles in the event. More specifically, particle flow algorithms link tracks in the tracker to energy deposits in the calorimeters or tracks in the muon system. Energy deposits that have no tracks associated with them are assumed to be due to neutral particles. Ultimately, effective tracking algorithms are necessary before most particles can be identified.

\qquad Tracking algorithms build up the full tracks iteratively. Track construction begins by identifying hits in the pixel layer. There must be hits in at least three pixel layers with an energy of at least 200 MeV ~\cite{Chatrchyan:2014fea} These collections of hits are used to seed a track. The track is then propagated to subsequent layers of the tracker by a Kalman Filter technique ~\cite{Fruhwirth:1987fm}. A $\chi^2$ fit is then used to identify the silicon strip hits that best correspond to the pixel triplets. All hits in the track are then removed from the list of hits to consider, and the algorithm is repeated for subsequent collections of pixel triplets and silicon strip deposits. This is shown in figure ~\ref{fig:iteratetrack}.

\begin{figure}[here]
\includegraphics[width=1.1\textwidth]{iterative_tracking.jpg}
\caption{A visual depiction of the iterative tracking algorithm\cite{Tosi:1956757}. First, pixel triplets (in red) are identified.  Secondly, the best match of pixel hits and track hits is identified. Finally, the identified track is removed and the algorithm finds the second best track candidate. }
\label{fig:iteratetrack}
\end{figure}


\qquad Nuclear interactions in the tracker material can cause tracks to appear displaced. These interactions are identified by linking three tracks to a common secondary vertex. A secondary vertex is a vertex that is displaced from the primary vertex of the collision. The primary vertex is identified by selecting the vertex with the highest $p_{T}^{2}$ sum of its associated tracks. A primary track is required to link the secondary vertex to the primary vertex. The tracks linked to the secondary vertex are required to have an invariant mass greater than 200 MeV. These secondary vertices are distinguished from those discussion in section \ref{bjets} by their distance from the beam axis. Identified secondary vertices from b-jets are required to form within $d_{xy} <$ 0.2 cm of the beam axis, but as discussed in section \ref{tracker}, the innermost component of the tracker is located at $d_{xy} =$ 4 cm from the beam axis. 


\qquad After identifying the tracks, their positions are extrapolated to associate them with energy deposits in other parts of the detector. Due to the magnetic field, the radius of the track will depend on the particle's momentum. The momentum of the track is compared to the energy measured in the calorimeters or the muon system to determine if the track was associated with the deposit. In this way, tracks and calorimeter deposits are linked together to reconstruct each particle of the event. Each particle type has its own unique reconstruction conditions, which are described below.

\section{Electrons}\label{electrons}

\qquad Electrons are identified by associating tracks found in the ECAL to objects known as "superclusters." As electrons interact with the tracker, they will lose kinetic energy in the form of radiated photons. This is known as bremsstrahlung radiation ~\cite{griffiths1999introduction}. These radiated photons are not affected by the magnetic field of CMS. As a result, the electron energy will be spread out in $(\eta,\phi)$ in the ECAL because the radiated photons are unaffected by the magnetic field. 

\qquad Tracks from the standard iterative tracking procedure (section \ref{pflow} are used as electron candidates. Their $p_{T}$ is required to be greater than 2 GeV. The electrons may not interact substantially with the tracker, so if the track is propagated to the ECAL (Section \ref{ecal}) and if its $p_{T}$ matches the ECAL cluster deposit, then the track is pre-identified as an electron. Otherwise the track is fit with a Gaussian-sum filter (GSF) to account for the non-Gaussian energy loss~\cite{Adam:815410} in the tracker. A boosted decision tree ~\cite{Hocker:2007ht} is then used to select the final GSF electron track candidates.  

\qquad Photons are neutral particles and will therefore not leave any tracks in the tracker. Bremsstrahlung photons are reconstructed by examining tangents to the tracks at each tracker layer, where the bremsstrahlung radiation may have occurred as the electrons passed through the layer. These tangent tracks are extrapolated to the ECAL. If any of the extrapolated bremsstrahlung photon tracks are associated with clusters in the ECAL then those ECAL clusters are considered part of the electron supercluster. A similar procedure is used to add clusters associated with bremsstrahlung photon $e^{+}e^{-}$ pair production. Tracks associated with the supercluster have a high probability of being associated with jets or other particles. A more sophisticated method is needed to properly associate electron tracks with the supercluster.

\qquad The GSF electron tracks are matched to an ECAL supercluster of at least 10 GeV. No more than 10$\%$ of the ECAL energy should be found in a topologically linked section of the HCAL. A boosted decision tree ~\cite{Hocker:2007ht} takes as inputs the ECAL energy, HCAL energy, GSF track quality, among other parameters, and is trained to identify electrons. If there is no associated GSF track the particle flow candidate is defined as a photon. The reconstruction efficiency for electrons is about 90$\%$ for $p_{T} > 20$ GeV. ~\cite{Khachatryan:2015hwa}

\qquad In the 2012 analyses at $\sqrt{s}$ = 8 TeV, a cut based ID is used \cite{Khachatryan:2015hwa}. The cuts used differ between the calorimeter barrel ($|\eta| < 1.479$) and the endcap ($1.479 < |\eta| < 2.5$). In the barrel, the extension of the shower in the $\eta$ direction ($\sigma_{\eta\eta}$) is required to be less than 0.01. The ratio of the energy deposits ($H/E$) between the HCAL (section \ref{hcal}) and the ECAL (section \ref{ecal}) must be less than 0.12.    The distances from the vetex, $d_{0}$ and $d_{Z}$ (section \ref{cms}) must be less than 0.02 cm and 0.2 cm respectively. The supercluster energy $E_{SC}$ and the track momentum at the closest point to the vertex ($p$) are also used as discriminators, with the requirement that $1/E_{SC} - 1/p < 0.05$. In the endcap the $\sigma_{\eta\eta}$ cut is loosened to 0.03 and the $H/E$ cut is tightened to 0.10.

\qquad In the 2015 analyses at $\sqrt{s}$ = 13 TeV, a boosted decision tree is used to optimize the electron selection. MVA discriminators are used to require an electron efficiency of 90\%.

\qquad Electrons are required to be isolated from additional particles in the event. The $p_{T}$ of charged hadrons, neutral hadrons, and photons is summed within a cone of radius $\Delta R < 0.3$ around the electron.  Corrections are applied for additional particles not associated with the primary vertex (pileup). The particle flow isolation is defined as $I_{PF}^{e} = \left(\sum\limits^{Ch. had} p_{T} + max(0, \sum\limits^{N. had.} p_{T} + \sum\limits^{\gamma} p_{T} - 0.5 \sum\limits^{PU} p_{T}\right)/p_{T}^{e}$. The factor of 0.5 corresponds to an approximate average ratio of neutral to charged particles, as measured in jets \cite{CMS-PAS-PFT-10-002}. Alternatively, the effective area method can be used to estimate the pileup. The contribution from the pileup, $p_{T}^{PU}$, is defined as $p_{T}^{PU} = \rho A_{eff}$. Here $\rho$ is the average energy density in the event, defined as the median of the energy density distribution for particles within the area of any jet (section \ref{jets}) in the event.\cite{Khachatryan:2015hwa} FASTJET \cite{Cacciari:2011ma} is used to determine $A_{eff}$, the effective area of of the clustered jet.  


\section{Muons}\label{muons}
\qquad Muons are highly penetrating particles~\cite{Agashe:2014kda} that deposit a minimal amount of energy in the ECAL and HCAL before depositing the remainder of their energies in the muon system. The muon system is discussed further in Section \ref{muonsys}. 

\qquad Muons are identified in three different ways. Standalone muons are identified based on hits in the DT, CSC, and RPC elements of the muon system. Hits in the DT's and CSC's are used as a seeds for a Kalman Filter (section \ref{pflow}) fit of the DT, CSC, and RPC hits. The resulting track is defined as a standalone muon.~\cite{Chatrchyan:2013sba} If a standalone muon track is matched to a tracker track, then the two tracks are combined using the Kalman Filter technique to identify a global muon. At high $p_{T} > 200$ GeV global muons have improved momentum resolution compared to standalone muons.

\qquad Tracker muons are constructed by extrapolating all tracker tracks with $p_{T} > 0.5$ GeV and $p > 2.5$ GeV to the muon system. If the track matches a small segment of DT and CSC hits, the track is considered to be a tracker muon. Tracker muons improve efficiency for muons with low $p_{T} < 5$ GeV because low energy muons won't register enough hits in the muon system to be identified as standalone or global muons.

\qquad The muon algorithms are very efficient, with approximately 99$\%$ of muons successfully identified in the tracker or the muon system.~\cite{Chatrchyan:2013sba} To reduce the fake rate due to hadrons punching through the calorimeters, global muons are required to be isolated, with no more than 10$\%$ of their energy measured by the calorimeters or the tracker inside a cone of $\Delta R < 0.3$. Additionally, charged hadrons may be reclassified as muons if their is a large discrepancy between their track $p_{T}$ and the sum of their particle flow linked calorimeter deposits. 

\qquad Additional tight identification criteria are applied to muons used in the analyses in sections \ref{lfv} and \ref{wjets} Global muons are required to be within $d_{xy} <$ 0.2 cm and $d_{z} <$ 0.5 cm of the primary vertex. Muons are required to have recorded at least one hit in the pixel system (section \ref{tracker}) and hits in at least six tracker layers. A particle flow based isolation requirement is defined for muons, analogous to the definition for electrons in section \ref{electrons}. 
$I_{PF}^{\mu} = \left(\sum\limits^{Ch. had} p_{T} + max(0, \sum\limits^{N. had.} p_{T} + \sum\limits^{e,\gamma} p_{T} - 0.5 \sum\limits^{PU} p_{T}\right)/p_{T}^{\mu}$. The isolation is computed in a radius of $\Delta R < 0.4$. 


\section{Hadrons}\label{hadrons}
Hadrons are identified after the unique signatures of electrons, photons, and muons are already identified and removed from the list of remaining particle flow candidates. Neutral hadrons will only deposit energy in the calorimeters, while charged hadrons have associated tracks. For charged hadrons, the uncertainty in $p_{T}$ returned by the track fit must be smaller than the calorimeter energy resolution for charged hadrons, described in Sections \ref{ecal} and \ref{hcal}. The hadronic deposits are used to reconstruct jets and hadronic tau decays.

\subsection{Jets}\label{jets}
\qquad After hadronic deposits are reconstructed via particle flow, the anti-$k_{t}$ ~\cite{Cacciari:2008gp} algorithm is used to cluster the deposits and define jets. A distance metric between hadronic particles $i$ and $j$ is defined: $d_{ij} = min(\frac{1}{k_{ti}^{2}},\frac{1}{k_{tj}^{2}})\frac{\Delta_{ij}^{2}}{R^{2}}$. Here $k_{t}$ is the transverse momentum and $\Delta_{ij}^{2} = (y_{i}-y_{j})^{2} + (\phi_{i} - \phi_{j})$, where $y$ and $\phi$ are the rapidity and azimuth of the particle, as defined in section \ref{cms}. At CMS, a radius of $R = 0.5 (0.4)$ is used at 8 TeV (13 TeV). The radius is chosen to mimize the effect of pileup on the energy of the clustered jet. The distance between particle $i$ and the beam is defined as $d_{iB} = \frac{1}{k_{ti}^{2}}$.

\qquad Beginning from a particle $j$, neighboring particles $i$ are combined while $d_{ij} < d_{ib}$. Otherwise, $i$ is considered the seed for a different jet. The results of this algorithm are show in Figure ~\ref{fig:antikt}. The anti-$k_{t}$ algorithm is infrared safe and collinear safe~\cite{Cacciari:2008gp} which means that the jet clustering process is not affected significantly by low energy soft radiation. The anti-$k_{t}$ algorithm is applied to jets at CMS via the FASTJET framework\cite{Cacciari:2011ma}.

\begin{figure}[here]
\includegraphics[width=0.9\textwidth]{antikt.jpg}
\caption{Performance of the anti-$k_{t}$ algorithm.~\cite{Cacciari:2008gp} Note that the anti-$k_{t}$ algorithm is the only algorithm that generates a circular hard jet. }
\label{fig:antikt}
\end{figure}

\qquad Charged hadron subtraction is used to reduce the dependence of the jets on pileup (Section \ref{ppcoll}) The majority of jet energy is carried by charged hadrons. For example, at $p_{T} = 100$ GeV charged hadrons are responsible for 65$\%$ of the jet energy. Photons carry 25$\%$ of the energy and neutral hadrons carry 10$\%$ of the energy. The charged hadron constituents of the jets still have track information stored via the particle flow algorithm. Any charged hadrons associated with pileup vertices instead of the primary vertex are retroactively removed from the jet.~\cite{Kirschenmann:1627818}

\qquad Multiple types of corrections are applied to the jets. First, the average $p_{T}$ density per unit area is used to estimate the soft jet activity, which is associated with a combination of the underlying event, electronic noise, and pileup ~\cite{Kirschenmann:1627818}. This energy is subtracted using $\eta$ and $p_{T}$ dependant scale factors. The next level of corrections use Monte Carlo to calibrate the differences between reconstructed jets and generated jets in bins of $p_{T}$ and $\eta$. This step is designed to account for detector imperfections, such as a non-linear $p_{T}$ response of the calorimeters or variations in response with respect to $\eta$. Finally, data-driven residual scale factors are computed by measuring jet $p_{T}$ imbalances in dijet events and Z/$\gamma$+jets.

\qquad Jets which originate from pileup rather than the hard scattering process of interest are identified and removed. A boosted decision tree is trained using a Z+jets Monte Carlo sample produced with MADGRAPH and PYTHIA. Jet shower shape and vertex related variables are used as inputs to identify reconstructed jets which are not matched to a generator level hard scattering process. \cite{CMS-PAS-JME-13-005} 

\subsubsection{B-Jets}\label{bjets}
\qquad Jets which originate from b quark decays are referred to as b-jets. B quarks produced in the hard scattering event can travel a measurable distance before decaying. B-jets are identified by finding jets which originate from a secondary vertex, displaced in $d_{xy}$ from the primary vertex. Secondary vertices are required to share less than 65\% of their associated tracks with the primary vertex and have at least a 3$\sigma$ radial distance significance from the primary vertex. The secondary vertices must be within $d_{xy} <$0.2 cm and $d_{z} <$17 cm of the primary vertex, which accounts for the time it takes the b quark to hadronize. The tracks from the secondary vertices must have $p_{T} >$ 1 GeV and have at least eight associated hits in the tracker. Tracks that pass these requirements are used as inputs in the Combined Secondary Vertex (CSV) algorithm. This algorithm identifies b-jets using vertex and tracker related variables to identify b-jets and is trained with a $t\bar{t}$ sample. The b-tagging efficiency is 85\%. \cite{Chatrchyan:2012jua}

\subsection{Taus}\label{taus}

\qquad As discussed in Chapters \ref{theory} and \ref{pheno}, taus can decay leptonically to electrons or muons, or hadronically to quarks. Taus are identified separately depending on their decay products, so the identification of leptonic tau decays has already been discussed in Sections \ref{muons} and \ref{hadrons}, which describe the identification of electrons and muons respectively. This section will discuss the identification of hadronic taus. As discussed in Chapter \ref{pheno}, taus can decay hadronically in three dominant ways: To a charged pion, to a charged pion and a neutral pion, or to three pions. These decays have branching fractions of 11.6\%, 26.0\%, and 9.8\%, respectively.

\qquad If the tau decays exclusively to charged hadrons, the hadronic tau ($\tau_{h}$) is identified by comparing the invariant mass of the hadrons to the invariant mass of the tau. For example, if the tau decays to three charged pions, the invariant mass of the decay products must be between 0.8 GeV and 1.5 GeV, and the tracks must originate within $\Delta z < 0.4$ cm of the same event vertex ~\cite{1748-0221-7-01-P01001}, where $\Delta z$ is the distance in the x-y plane of CMS, as discussed in Section \ref{cms}. Mass windows of 50-200 MeV and 0.3-1.3 GeV are used for charged pion decays and charged pion plus neutral pion decays, respectively. 

\qquad If a neutral pion is involved in the hadronic tau decay, then the hadron plus strips (HPS) method must be used to identify the taus. Neutral pions convert to energetic photons in the tracker which then produce electron positron pairs. These particles will be bent in opposite directions in the magnetic field of CMS and will deposit their energy in the ECAL in a strip in $\phi$. The maximal distance between hadronic tau candidates and strips is $\Delta R = 3.0/p_{T}^{\tau}$. The strip sizes are 0.05 $\times$ 0.20 in the ($\eta$,$\phi$) plane. The size is elongated in $\phi$ because the $e^{+}e^{-}$ pair will be bent in $\phi$ due to the magnetic field. In 13 TeV, the strip sizes are allowed to vary in a dynamic way that depends on the $p_{T}$ weighted average of all $e/ \gamma$ objects in the strip. The strip size is allowed to vary from (0.05,0.05) to (0.15,0.30) in the ($\eta$,$\phi$) plane.If a charged hadron from particle flow is linked to a strip in ECAL, and the invariant mass of the system is compatible with the hadronic tau mass, then the object is identified as a tau. The probability to reconstruct the tau decay mode is 80\%, as measured in $Z \rightarrow \tau\tau$ events.

\qquad The particle flow tau isolation, $I_{PF}^{\tau}$, is computed by summing momenta of particle flow candidates within a cone of $\Delta R$ = 0.5 (0.4 at 13 TeV) around the tau. $I_{PF}^{\tau} =  \sum\limits^{Ch. had} p_{T} + \sum\limits^{N. had.} p_{T} + \sum\limits^{\gamma} p_{T} - 0.4576 \sum\limits^{PU} p_{T}$ The 0.4576 factor is chosen to make the ID independent of pileup. The tight working point requires $I_{PF}^{\tau} <$ 0.8 GeV and has an ID efficiency of 50 \% in 8 TeV data. \cite{CMS-DP-2014-015}

\section{Missing Energy} \label{met}
\qquad There are some particles, for example neutrinos or dark matter candidates, that CMS cannot detect. They can be measured by applying the principle of conservation of momentum. The transverse vector sum of all particle flow candidates in the event is computed. If CMS detected every particle, this sum would be zero. Therefore, the energy that CMS did not detect can be quantified by reversing the vector sum of the particles that were detected. If the jet energy corrections are included in the vector sum, the transverse missing energy (MET) is said to be Type 1 corrected ~\cite{Khachatryan:2014gga}

\chapter{Lepton Flavor Violating decays of the Higgs Boson}\label{lfv}
\qquad A search for a lepton flavor violating (LFV) decay of a Higgs boson is performed in two channels: $H \rightarrow \mu\tau_{e}$ and $H \rightarrow \mu\tau_{h}$, where $\tau_{h}$ and $\tau_{e}$ are taus reconstructed in the hadronic and electronic decay channels respectively. As mentioned in section \ref{higgspheno}, these channels have a similar signature as the Standard Model $H \rightarrow \tau_{\mu} \tau_{had}$ and $H \rightarrow \tau_{mu}\tau_{e}$ searches, with a significant kinematic difference due to the muon arising directly from the Higgs decay. All the neutrinos in the event will arise from the tau decay. Because the tau is heavily boosted, the neutrinos will be collinear with the visible tau decay products. The term "visible decay products" is used to denote the tau decay products that CMS can detect directly, which are electrons, muons, and hadrons. Neutrinos register as missing energy in the event and are detected indirectly as discussed in section \ref{met}. The missing transverse energy in the event is the sum of the energy of all unidentified particles, so the individual neutrino momenta cannot be measured directly. In order to calculate the invariant mass (section \ref{kindef}) of the final state objects the collinear approximation must be used.

\qquad The collinear approximation\cite{Ellis:1987xu} arises from the observation that since the mass of the Higgs is much greater than the mass of the tau, the tau decay products are highly boosted in the direction of the original tau. Therefore, the neutrino momentum can be approximated to be in the same direction as the other visible decay products of the tau. The component of the missing transverse energy in the direction of the visible tau decay products is used to estimate the transverse component of the neutrino momentum:

\begin{equation}
\vec{p}_{T}^{\nu} = \vec{E}_{T}^{miss} \dot \hat{p}_{T}^{\tau_{vis}}
\end{equation}

The fraction of the tau momentum carried by the visible tau decay products, $x_{\tau_{vis}}$, is given by:

\begin{equation}
x_{\tau_{vis}} = \frac{|\vec{p}_{T}^{\tau_{vis}}|}{|\vec{p}_{T}^{\tau_{vis}}| + |\vec{p}_{T}^{\nu}|}
\end{equation}

The tau four momentum is then $\frac{1}{x_{\tau_{vis}}}\left(|\vec{p}^{\tau_{vis}}|,\vec{p}^{\tau_{vis}}\right)$. The mass of the Higgs boson is much greater than the mass of the tau or muon or electron, so the approximation $M_{H} \gg m_{\tau}^2,m_{l}^2$ is valid. This yields the collinear mass equation:

\begin{equation} 
M_{H} = M_{collinear} = \frac{M_{vis}}{\sqrt{x_{\tau_{vis}}}}
\end{equation}

The Higgs mass has now been defined in terms of the mass of the visible decay products, which can be directly measured by CMS. As shown in figure \ref{fig:MvisMcol} the collinear mass gives an improved mass resolution over the visible mass, in addition to peaking at the expected value of 125 GeV. 

\begin{figure*}[hbtp]\begin{center}
\includegraphics[height=5.5cm]{masses_muhad_VBF_After_Presel_signal.pdf}
 \caption{$M_{vis}$  and $M_{collinear}$  shape comparisons after the pre-selection for the $H \rightarrow \mu\tau){h}$ channel}
 \label{fig:MvisMcol}\end{center}\end{figure*}

\section{8 TeV Backgrounds and Datasets}
\subsection{Data}
\qquad The search is performed on the 2012, $\sqrt{s}$ = 8 TeV dataset, comprising 19.7$fb^{-1}$ of data. The $H \rightarrow \mu\tau_{had}$ channel selection requires an isolated single muon trigger with a $p_{T}^{\mu}$ threshold of 24 GeV in the range $|\eta| < 2.1$, while the $H \rightarrow \mu\tau_{e}$ channel requires a muon-electron trigger with $p_{T}$ threshold of 17 GeV ($|\eta| < 2.5$) and 8 GeV ($|\eta| < 2.4$), respectively. 
\subsection{LFV Higgs and SM Higgs}
\qquad The signal decay $H \rightarrow \mu\tau$ is implemented via PYTHIA8. This version of PYTHIA8 contains decay mechanisms that account for tau polarization and spin, and the interface with Tauola is not needed\cite{Sjostrand:2014zea}. The Standard Model $H \rightarrow \tau\tau$ background is modelled using PYTHIA 6 and Tauola. In addition to the generators, the full GEANT detector simulation is used for each Monte Carlo sample.

%\qquad The largest Monte Carlo backgrounds, such as $Z \rightarrow \tau\tau$ and W+jets, are estimated using data and the smaller backgrounds are estimated with simulation. 
\subsection{Z to tau tau}
\qquad The $Z \rightarrow \tau\tau$ background is estimated using a particle flow embedding technique. A sample of $Z \rightarrow \mu\mu$ events is taken from data using a loose selection. The muons are then replaced with simulated tau decays reconstructed with the particle flow algorithm. The key features of the event topology, such as the jets, missing energy, and underlying event, are taken directly from data. Only the tau decays are simulated. The sample is normalized in accordance with the Monte Carlo expectation, using Drell Yan events generated with MADGRAPH and PYTHIA6.
\subsection{Misidentified Leptons}\label{fakes}
\qquad Jets may be mistakenly identified as leptons. These misidentified leptons are referred to as "fakes." Misidentified leptons are produced by jets in W+Jets and QCD multi-jet events. The W+Jets background is particularly significant as the largest irreducible background in this analysis. If a jet is misidentified as a tau and the W boson decays muonically, then the kinematics of the event may be identical to the LFV signal: a muon, a tau, and missing energy opposite to the muon. This background is estimated using a data driven method. The same preselection cuts are used, but the isolation of one of the leptons is inverted, so that is it surrounded by other PF objects in the event. This enriches the contributions from W+jets and QCD multijet events and gives a larger sample of data statistics for estimating the background. The probability for particle flow objects to be misidentified as leptons is measured in an independant collision data set, and this probability is applied to the background enriched sample to compute the misidentified lepton background in the signal sample. This technique is shown schematically in Table 4 in which four regions are defined. Regions I and III are the signal and background enriched regions, respectively, and Regions II and IV are the control regions, with the same selections as Regions I and III but with a same sign lepton requirement. The control regions are designed to maximize the number of fake lepton events while minimizing other backgrounds in order to directly test the accuracy of the fake rate method. This technique is illustrated in Table \ref{tab:fakeratediagram}.

\begin{table}[hbt]
 \centering
 
 \renewcommand{\arraystretch}{1.1}
 \caption{Definition of the regions used to estimate the misidentified lepton background. The different regions have different requirements for the
isolation and the relative charge of the two leptons $\ell^{\pm}_{1}$ and $\ell^{\pm}_{2}$, which can be $e$, $\mu$ or $\tau_{h}$.}
  \label{tab:fakeratediagram}
  
  \begin{tabular}{c|c}  
  Opposite-sign leptons & Same-sign leptons \\
  \hline
% \rule[-5pt]{0pt}{20pt}
\textbf{Region I}              &  \textbf{Region II}             \\ \hline
$\ell^{\pm}_{1}$(isolated)  &  $\ell^{\pm}_{1}$(isolated)             \\
$\ell^{\mp}_{2}$(isolated)  &  $\ell^{\pm}_{2}$(isolated)             \\

\hline \hline
% \rule[-5pt]{0pt}{20pt}
\textbf{Region III}           &  \textbf{Region IV}             \\ \hline
$\ell^{\pm}_{1}$(isolated)  &  $\ell^{\pm}_{1}$(isolated)             \\
$\ell^{\mp}_{2}$(non-isolated )  &  $\ell^{\pm}_{2}$(non-isolated)             \\
\hline
  \end{tabular}
  
\end{table}


\qquad In the $H \rightarrow \mu\tau_{e}$ channel, Region I is the signal region in which an isolated muon and an isolated electron are required. In Region III all the analysis selection criteria are applied to the data sample, with the exception that one of the leptons is required to be non-isolated. This creates a region enriched with misidentified leptons. There are two types of events in this region: those with an isolated muon and a non-isolated electron and those with an isolated electron and a non-isolated muon. There are a negligible number of signal events in Region III. Regions II and IV are defined using the same selection criteria as Region I and III, respectively, but same-sign leptons are required instead of opposite sign leptons. The sample in region III is dominated by W+jets and QCD multijets. The misidentified electron background in Region I is estimated by multiplying the event yield in Region III by a factor $f_{e}$, where $f_{e}$ is the ratio of non-isolated to isolated electrons. It is computed in an independent data sample $Z \rightarrow \mu\mu + X$, which $X$ is a particle flow object identified as an electron. Background sources of real leptons, such as diboson events, are subtracted from the $Z \rightarrow \mu\mu +X$ sample using Monte Carlo simulation. The misidentified muon background is computed in the same way. The technique is validated using the same-sign data from regions II and IV. In Figure \ref{fig:samesign_fakes} the observed data yield in Region II is compared to the estimate obtained by scaling the Region IV sample by the measured misidentification rates.

\begin{figure*}[hbtp]\centering
\includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/fakesEle_log.pdf}
\includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/fakes_log.pdf}
\caption{Distributions of $M_\text{col}$ for region II compared to the estimate
from scaling the region IV sample by the measured misidentification rates at $\sqrt{s}$ = 8 TeV. The bottom panel in each plot shows the fractional difference between the observed data and the estimate. Left:  $H \rightarrow \mu \tau_{e}$. Right: $H \rightarrow \mu \tau_{h}$. }
\label{fig:samesign_fakes}\end{figure*}


\qquad In the $H \rightarrow \mu\tau_{h}$ channel, the $\tau_{h}$ candidate can arise from a misidentified jet coming predominantly from W+jets and QCD multijet events. The misidentification rate $f_{\tau_{h}}$ is measured in $Z \rightarrow \mu\mu +X$ events selected in data, where $X$ is an object identified as a $\tau_{h}$ candidate that passes a loose isolation requirement. The factor $f_{\tau_{h}}$ is defined as the fraction of these loosely isolated $\tau_{h}$ candidates that pass the tighter isolation requirement used to define the signal region. The misidentification rate measured in $Z\rightarrow \mu\mu+X$ collision data is compared to the measured rate in simulation and is found to be in agreement.

\qquad The enriched background regions (III and IV) are defined by requiring the presence of $\tau_{h}$ candidates that pass the looser isolation requirement, but do not pass the tight isolation requirement. The misidentified background yield in the signal region (Region I) is estimated by multiplying the event yield in Region III by a factor $\frac{f_{\tau_{h}}}{1-f_{\tau_{h}}}$. The procedure is validated with same-sign $\mu\tau_{h}$ events (Region II) using Region IV to model the misidentified background, in the same way as for the $H \rightarrow \mu\tau_{e}$ channel. The control region for the $H \rightarrow \mu\tau_{h}$ channel is shown in Figure \ref{fig:samesign_fakes}.

\subsection{Additional Backgrounds}

\qquad The remaining backgrounds play a small role in the analysis and are all estimated with simulation. MADGRAPH5, PYTHIA6, and Tauola are used to simulate diboson events and events with one top quark and one antitop quark (ttbar events). POWHEG 1.0, PYTHIA6, and Tauola are used to simulated single top quark events.

\section{13 TeV Backgrounds and Datasets}

\qquad The search is performed on the 2015, $\sqrt{s}$ = 13 TeV dataset, comprising 2.3$fb^{-1}$ of data. The trigger selection requires an isolated single muon with $p_{T} >$ 20 GeV in the range $|\eta| < 2.4$.

\qquad The LFV and SM Higgs boson samples are generated using POWHEG 1.0, with CT10 parton distribution functions, interfaced to PYTHIA 8.212. The MADGRAPH 5.1.3.30 generator is used for Z+jets, $t\bar{t}$, and diboson production. POWHEG is used for single top production. The POWHEG and MADGRAPH generators are interfaced to PYTHIA for parton showering and hadronization. The misidentified lepton background is modeled using the fake rate method, as discussed in section \ref{fakes}. Comparisons between data and Monte Carlo in the Region II control region are show in Figure \ref{fig:samesign_fakes13TeV} 

\begin{figure*}[hbtp]\centering
\includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V2_MuonFix_March30/preselectionSS_collMass_type1_MuTau_AMCATNLO.pdf}
\includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/PreselectionSS_ForPAS/mue0J_preselection_SS.pdf}
\caption{Distributions of $M_\text{col}$ for region II compared to the estimate
from scaling the region IV sample by the measured misidentification rates at $\sqrt{s}$ = 13 TeV. The bottom panel in each plot shows the fractional difference between the observed data and the estimate. Left:  $H \rightarrow \mu \tau_{e}$. Right: $H \rightarrow \mu \tau_{h}$. }
\label{fig:samesign_fakes13TeV}\end{figure*}
  
\section{Event Selection}\label{eventsel}
\qquad The event selection consists of three steps. First, a loose preselection defines the basic signature. The events are then divided into three categories: 0 jet events, 1 jet events, and 2 jet events. Finally, cuts on relevant kinematic variables are optimized to suppress the backgrounds. 

\qquad The preselection for the $H \rightarrow \mu\tau_{e}$ channel requires an isolated tight muon (section \ref{muons}) with $p_{T} > 25 GeV$, $|\eta| < 2.1$, and an isolated tight election (section \ref{electrons}) of opposite charge, with $p_{T} > 10 GeV$, $|\eta| < 2.3$. The isolation requirement for the muon is $I_{PF}^{\mu} < 0.12$ at 8 TeV and $I_{PF}^{\mu} < 0.15$ at 13 TeV. The isolation requirement for the electron is $I_{PF}^{e} < 0.12$ at 8 TeV, and $I_{PF}^{e} < 0.10$ at 13 TeV. The effective area corrections for pileup subtraction are applied at 13 TeV. The $H \rightarrow \mu\tau_{h}$ channel requires an isolated tight muon with $p_{T} > 30 GeV$, $|\eta| < 2.1$, and a tightly isolated hadronic tau (section \ref{taus}) of opposite charge, with $p_{T} >$ 30 GeV, $|\eta| <$ 2.3. Events with additional leptons are vetoed.

\qquad The events are then divided into categories corresponding to the number of jets in the event. Jets are required to pass particle flow identification algorithms (section\ref{jets}), have $p_{T} > 30$ GeV and lie within $|\eta| < 4.7$. The zero jet category contains events primarily produced by gluon-gluon fusion. The one jet category is also dominated by gluon-gluon fusion events. The two jet category contains a significant number of vector boson fusion events. Events in the two jet category are required to have the jets separated by a rapidity gap ($\Delta\eta > 3.5$) and to have an invariant dijet mass greater than 550 GeV. In the $H \rightarrow \mu\tau_{e}$ channel events are vetoed if they contain a b-jet. Agreement between data and Monte Carlo simulation at preselection are show in figure \ref{fig:Mcol_after_presel_WITHDATA} for $\sqrt{s}$ = 8 TeV and in figure \ref{fig:Mcol_after_presel_WITHDATA_13TeV} for $\sqrt{s}$ = 13 TeV.

\begin{figure*}[hbtp]\centering
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/hlfv/muele_GG_m_colinear_UNBLIND_PRESEL_BR100.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/hlfv/muhad_GG_m_colinear_UNBLIND_PRESEL_BR100.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/hlfv/muele_Boost_m_colinear_UNBLIND_PRESEL_BR100.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/hlfv/muhad_Boost_m_colinear_UNBLIND_PRESEL_BR100.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/hlfv/muele_VBF_m_colinear_UNBLIND_PRESEL_BR100.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/hlfv/muhad_VBF_m_colinear_UNBLIND_PRESEL_BR100.pdf}
 \caption{Distributions of the collinear mass $M_{collinear}$ at $\sqrt{s}$ = 8 TeV, for signal with $B(H \rightarrow \mu \tau )=100\%$ for clarity, and background processes after the loose selection requirements for the LFV $H \rightarrow \mu \tau$ candidates for the different channels and categories compared to data. The shaded grey bands indicate the total uncertainty. The bottom panel in each plot shows the fractional difference between the observed data and the total estimated background.  Top left: $H \rightarrow \mu \tau_{e}$ 0-jet; top right: $H \rightarrow \mu \tau_{h}$ 0-jet;  middle left: $H \rightarrow \mu \tau_{e}$ 1-jet; middle right: $H \rightarrow \mu \tau_{h}$
1-jet; bottom left: $H \rightarrow \mu \tau_{e}$ 2-jet; bottom right $H \rightarrow \mu \tau_{h}$ 2-jet. }
 \label{fig:Mcol_after_presel_WITHDATA}\end{figure*}

\begin{figure*}[hbtp]\centering
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/lfv/PreselectionEMu_ForPAS/mue0J_preselection.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/lfv/76X_V2_MuonFix_March30/preselection0Jet_collMass_type1_MuTau_AMCATNLO.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/lfv/PreselectionEMu_ForPAS/mue1J_preselection.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/lfv/76X_V2_MuonFix_March30/preselection1Jet_collMass_type1_MuTau_AMCATNLO.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/lfv/PreselectionEMu_ForPAS/mue2J_preselection.pdf}
 \includegraphics[width=0.42\textwidth]{/home/aaron/root/lfv/76X_V2_MuonFix_March30/preselection2Jet_collMass_type1_MuTau_AMCATNLO.pdf}
 \caption{Distributions of the collinear mass $M_{collinear}$ at $\sqrt{s}$ = 8 TeV, for signal with $B(H \rightarrow \mu \tau )=100\%$ for clarity, and background processes after the loose selection requirements for the LFV $H \rightarrow \mu \tau$ candidates for the different channels and categories compared to data. The shaded grey bands indicate the total uncertainty. The bottom panel in each plot shows the fractional difference between the observed data and the total estimated background.  Top left: $H \rightarrow \mu \tau_{e}$ 0-jet; top right: $H \rightarrow \mu \tau_{h}$ 0-jet;  middle left: $H \rightarrow \mu \tau_{e}$ 1-jet; middle right: $H \rightarrow \mu \tau_{h}$
1-jet; bottom left: $H \rightarrow \mu \tau_{e}$ 2-jet; bottom right $H \rightarrow \mu \tau_{h}$ 2-jet. }
 \label{fig:Mcol_after_presel_WITHDATA_13TeV}\end{figure*}

\qquad Next, a set of kinematic variables are defined and the criteria for selection is determined by optimizing for $\frac{S}{\sqrt{S+B}}$ for the $\sqrt{s}$ = 8 TeV dataset, where S and B are the expected signal and background event yields in the mass window 100 GeV < $M_{collinear} <$ 150 GeV. The signal strength is set as $B(H\rightarrow\mu\tau) = 10\%$. The $10\%$ value was chosen because it corresponds to the limit from indirect measurments, as mentioned in section \ref{BSM}. The criteria for each category, and in each channel, are given in Table \ref{tab:kinematicselection}. The optimization was also performed assuming $B(H\rightarrow\mu\tau) = 1\%$ and a negligible change in the optimal selection criteria was observed. The variables used are the lepton transverse momenta $p_{T}^{\ell}$ with $\ell = \tau_{h},\mu,e$, azimuthal angles between the leptons 
$\Delta\phi_{\vec{p}_{T}^{\ell_{1}}-\vec{p}_{T}^{\ell_{2}}}$, azimuthal angle 
$\Delta\phi_{\vec{p}_{T}^{\ell}-\vec{E}_{T}^{miss}}$, and the transverse mass 
$M_{T}^{\ell} = \sqrt{2 p_{T}^{\ell}E_{T}^{miss}(1-cos \Delta\phi_{\vec{p}_{T}^{\ell}-\vec{E}_{T}^{miss}})}$. 

\begin{table}[hbtp]
 \centering
 \caption{Selection criteria for the kinematic variables after the loose selection.}
  \label{tab:kinematicselection}
   {\begin{tabular}{lccc|ccc} \hline
Variable & \multicolumn{3}{c|}{$H \rightarrow \mu \tau_{e}$} &      \multicolumn{3}{c}{$H \rightarrow \mu \tau_{h}$}  \\ \cline{2-7}
      [GeV]                                   &  0-jet        & 1-jet       & 2-jet         &  0-jet         & 1-jet       & 2-jet  \\ \hline
$p_{T}^{\mu}>$                                &     50        &   45        &   25          &  45            & 35          &  30    \\
$p_{T}^{e}>$                                  &     10        &   10        &   10          &   -            &  -          &  -      \\
$p_{T}^{\tau_{h}}>$                               &     -         &    -        &    -          &  35            & 40          &  40    \\
$M_{T}^{e}<$                                   &    65         &   65        &   25          &    -           &   -         &  -      \\
$M_{T}^{\mu}>$                                 &    50         &   40        &   15          &    -           &   -         &  -      \\
$M_{T}^{\tau_{h}}<$                                &     -         &    -        &    -          &  50            & 35          &   35   \\   \hline
      [radians]                               &                     &                \\  \hline
$\Delta\phi_{\vec{p}_{T}^{\mu}-\vec{p}_{T}^{\tau_{h}}}>$   &     -         &    -        &    -          &  2.7           &  -          &  -      \\
$\Delta\phi_{\vec{p}_{T}^{e}-\vec{E}_{T}^{miss}}<$             &    0.5        &   0.5       &   0.3         &    -           &  -          &  -      \\
$\Delta\phi_{\vec{p}_{T}^{e}-\vec{p}_{T}^{\mu}}>$            &    2.7        &   1.0       &    -          &    -           &   -         &  -      \\  \hline

  \end{tabular}
}
\end{table}

\qquad At $\sqrt{s}$ = 13 TeV, the 8 TeV optimization is re-used. Due to the lower integrated luminosity the cuts in the 2 jet category are loosened. The dijet mass requirement is loosened from 550 to 200 GeV and the rapidity gap requirement is decreased from $\Delta \eta > 3.5$ to $\Delta \eta > 2.5$. The electron $p_{T}$ requirement is increased from 10 to 15 GeV to suppress the misidentified electron background. 
\section{Systematic Uncertainties}\label{sysuncert}
\subsection{8 TeV}

\qquad To set upper bounds on the signal strength, or determine a signal significance, we use the $CL_{s}$ method (section \ref{statmeth}).  A binned likelihood is used, based on the distributions of $M_{collinear}$ for the signal and background sources. Systematic uncertainties are represented by nuisance parameters, some of which only affect the background and signal normalizations, while others affect the shape and/or normalization of the $M_{col}$ distributions. 

\subsubsection{Normalization Uncertainties}

\qquad The uncertainties are summarized in Tables \ref{tab:systematics} and \ref{tab:theory_systematics}. The uncertainties in the e and $\mu$ selection efficiency (trigger, identification, and isolation) are estimated using the "tag and probe" technique in $Z \rightarrow ee,\mu\mu$ data \cite{Chatrchyan:2014mua}. The identification efficiency of hadronic tau decays is estimated using the "tag and probe" technique in $Z \rightarrow \tau\tau$ data \cite{1748-0221-7-01-P01001}. The uncertainty in the $Z \rightarrow \tau\tau$ background comes predominantly from the uncertainty in the tau efficiency. The uncertainties in the estimation of the misidentified lepton rate come from the difference in rates measured in different data samples (QCD multijets and W+jets). The uncertainty in the production cross section of the backgrounds that have been estimated by simulation is also included.

\begin{table*}[t]
 \centering
  \caption{Systematic uncertainties in the expected event yield in \%. All uncertainties are treated as correlated between the categories, except where there are two numbers. In
this case the number denoted with * is treated as uncorrelated between categories and the
total uncertainty is the sum in quadrature of the two numbers.}
  \label{tab:systematics}
{
\begin{tabular}{lccc|ccc} \hline
Systematic  uncertainty                                &  \multicolumn{3}{c|}{$H \rightarrow \mu \tau_{e}$}& \multicolumn{3}{c}{$H \rightarrow \mu \tau_{h}$}    \\ \cline{2-7}
                                                       &  0-Jet  & 1-Jet  & 2-Jets     &  0-Jet    & 1-Jet     & 2-Jets     \\ \hline
electron trigger/ID/isolation                          &   3   &   3  &   3     &    NA      &   NA       &  NA        \\
muon  trigger/ID/isolation                             &   2   &   2  &   2     &    2    &  2      &  2      \\
hadronic tau efficiency                                &   NA     &   NA    &   NA       &    9    &  9      &  9      \\
luminosity                                             &  2.6  &  2.6 &  2.6    &  2.6    &  2.6    &  2.6    \\
$Z \rightarrow \tau \tau$ background                           &   3+3*&  3+5*&  3+10*  &   3+5*  &   3+5*  &   3+10* \\
$Z \rightarrow \mu\mu,ee$ background                           &   30  &  30  &  30     &   30    &   30    &   30    \\
misidentified $\mu,e$  background                      &  40   &  40  &  40     &    NA      &   NA       &   NA       \\
misidentified $\tau_{h}$  background                           &  NA      &   NA    &    NA      &   30+10*&  30     &  30     \\
$WW,ZZ$+jets background                                 &  15   &  15  &   15    &  15     &  15     &  65     \\
$t\bar{t}$ background                         &  10  &  10 &  10+10* &  10    &  10    &  10+33* \\
$W +\gamma$ background                                 &  100  &  100 &  100   &     NA     &    NA      &    NA       \\
b-tagging veto                                         &    3  &   3  &   3     &    NA      &    NA      &    NA       \\
single top production background                       &  10   &  10  &  10    &  10    &  10    &   10    \\ \hline
  \end{tabular}
}
\end{table*}

\begin{table*}[hbtp]
 \centering
  \caption{Theoretical uncertainties in \% for Higgs boson production. Anticorrelations arise due to  migration of events between the categories and are expressed as negative numbers. }
  \label{tab:theory_systematics}
  \begin{tabular}{lccc|ccc} \hline
Systematic uncertainty                  &  \multicolumn{3}{c|}{Gluon-Gluon Fusion} &  \multicolumn{3}{c}{Vector Boson Fusion}  \\ \cline{2-7}
                                &    0-Jets  & 1-Jets  & 2-Jets   & 0-Jet & 1-Jet  & 2-Jets  \\ \hline
parton distribution function         &    $+9.7$  &  $+9.7$ &   $+9.7$ & $+3.6$  &   $+3.6$  &  $+3.6$  \\
renormalization/factorization scale           &    $+8$    &  $+10$   &  $-30$   & $+4$     &   $+1.5$  & $+2$   \\
underlying event/parton shower  &   $+4$     & $-5$   &  $-10$   & $+10$    &   $<$1    & $-1$   \\ \hline
  \end{tabular}

\end{table*}


\qquad There are several uncertainties on the H production cross section, which depend on the production mechanism contribution and the analysis category. They are given in Table \ref{tab:theory_systematics}. These affect the LFV H and the SM H background equally, and are treated as 100\% correlated. The parton distribution function (PDF) uncertainty is evaluated b comparing the yields in each category, when spanning the parameter range of a number of different independent PDF sets including CT10 \cite{Nadolsky:2008zw}, MSTW \cite{Martin:2009iq}, NNPDF \cite{Ball:2010de}, as recommended by PDF4LHC \cite{Alekhin:2011sk}. The scale uncertainty is estimated by varying the renormalization and factorization scales, $\mu_{R}$ and $\mu_{F}$, up and down by one half or two times the nominal scale ($\mu_{R} = \mu_{F} = M_{H}/2$) under the constraint $0.5 < \mu_{F}/\mu_{R} < 2$. \cite{Dittmaier:2011ti}. The underlying event and parton shower uncertainty is estimated by using two different PYTHIA tunes, CUET2 and Z2*. Anticorrelations arise due to migration of events between the catories and are expressed as negative numbers
 
\subsubsection{Shape Uncertainties}

\qquad The systematic uncertainties that lead to a change in the shape of the $M_{collinear}$ distribution are summarized in Table 5. In the embedded $Z \rightarrow \tau\tau$ $M_{collinear}$ distribution, used to estimate the $Z \rightarrow \tau\tau$ background, a 1\% shift has been observed with respect to $Z \rightarrow \tau\tau$ simulations by comparing the means of both distributions. This only occurs in the $H \rightarrow \mu\tau_{e}$ channel. The $M_{collinear}$ distribution has been corrected for this effect and a 100\% uncertainty on this shift is used as a systematic uncertainty. The jet energy scale has been studied extensively and a standard prescription for corrections \ref{1748-0221-6-11-P11002} is used in all CMS analyses. The overall uncertainty is set using $\gamma$+jets events and the most significant uncertainty arises from the photon energy scale. A number of other uncertainties such as jet fragmentation modeling, single pion response, and uncertainties in the pileup corrections are also included. The jet energy scale uncertainties (3-7\%) are applied as a function of $p_{T}$ and $\eta$, including all correlations, to all jets in the event, and are also propagated to the missing energy. The unclustered energy scale comes from jets below 10 GeV and PF candidates not within jets. It also has its associated uncertainty which is propagated to the missing transverse energy. The tau energy scale is estimated by comparing $Z \rightarrow \tau\tau$ events in data and simulation. An uncertainty of 3\% is derived from this comparison. The uncertainty is applied by shifting the $p_{T}$ of the tau candidates in the event. Finally, the $M_{collinear}$ distributions used in the fit have a statistical uncertainty in each mass bin. This uncertainty is uncorrelated between the bins.

\qquad Uncertainties in the shape of the misidentified lepton backgrounds have also been calculated. In the $H \rightarrow \mu\tau_{e}$ channel the misidentified lepton ratios $f_{\mu},f_{e}$ are measured and applied in bins of lepton $p_{T}$ and $|\eta|$. These ratios are all adjusted up or down by one standard deviation and the differences in the shape of the resultant $M_{col}$ distributions are then used as nuisance parameters in the fit. In the $H \rightarrow \mu\tau_{h}$ channel the tau misidentification rate $f_{\tau}$ is found to be approximately flat in $p_{T}$ and $\eta$. To estimate the systematic uncertainty the $p_{T}$ distribution of $f_{\tau}$ is fit with a linear function and the rate recomputed from the fitted slope and intercept. 
\subsection{13 TeV}
\qquad The systematic uncertainties used in the 13 TeV analysis are similar to those used in the 8 TeV analysis. They are show in Table \ref{tab:systematics13TeV}. The 8 TeV analysis was carried out after many standard model studies had been completed, but the same is not true for the 13 TeV analysis. Therefore, a greater uncertainty is applied to the $Z \rightarrow \tau\tau$ and the $t\bar{t}$ backgrounds. The understanding of the $W+\gamma$ sample has increased significantly. The dominant theoretical uncertainties are  uncertainties in the GGF and VBF Higgs production cross section, which are determined by varying $\mu_{R}$, $\mu_{F}$, and PDF sets. The overall theoretical uncertainty is approximated to 10\%. 

\begin{table*}[t]
 \centering
  \caption{
Systematic uncertainties in the expected event yield in \%. All uncertainties are treated as correlated between the categories, except where there are two values. In
this case the first value is correlated as above, while the second value (following $\oplus$) represents an uncorrelated uncertainty for each individual category.
The total uncertainty in a given category is the sum in quadrature of the two values.}
  \label{tab:systematics13TeV}
{
\begin{tabular}{l|c|c} \hline
Systematic  uncertainty                                &  $H \rightarrow \mu \tau_{e}$ & $H \rightarrow \mu \tau_{h}$  \\ \hline
Muon  trigger/ID/isolation                             &              3\%           &    3\%   \\
Electron trigger/ID/isolation                          &              3\%           &    NA   \\
Hadronic tau efficiency                                &              NA           &    10\%  \\
b-tagging veto                                         &              3\%           &   NA    \\ \hline  \hline
$Z \rightarrow \tau \tau$ background                        &              10\%$\oplus$5\%          &    10\%$\oplus$5\%  \\
$Z \rightarrow \mu\mu,ee$ background                  &              10\%$\oplus$5\%          &    10\%$\oplus$5\%  \\
Misidentified $\mu,e$  background                   &              40\%$\oplus$10\%          &    NA   \\
Misidentified $\tau_{h}$  background                      &              NA           &    30\%$\oplus$10\%  \\
$WW,ZZ$ background               &              10\%$\oplus$5\%          &    10\%$\oplus$5\%  \\
$t\bar{t}$ background                                    &              20\%$\oplus$5\%          &    20\%$\oplus$5\%  \\
$W +\gamma$ background                               &              10\%$\oplus$5\%          &   NA    \\
Single top production background                       &               10\%         &   10\%   \\ \hline  \hline
Jet energy scale                                       &        3-20\%             &   3-20\% \\
Hadronic tau energy scale                              &        NA             &  3$\%$ \\
Misidentified lepton shape                             &        $\pm\sigma$              &  $\pm\sigma$  \\ \hline  \hline
Theory uncertainty                                     &              10\%          &    10\%  \\ \hline \hline
%%bin-by-bin                                             &      applied               &  applied \\ \hline \hline
Luminosity                                             &              2.7\%          &    2.7\%  \\ \hline
  \end{tabular}
}
\end{table*}

\section{Statistical Methods}\label{statmeth}
\subsection{Maximum Likelihood Fit}
\qquad After selecting events which pass the signal region selections (section \ref{eventsel}) and defining sources of systematic uncertainty (section \ref{sysuncert}), the next step is to fit the backgrounds to the data. This is done via a binned maximum likelihood fit.\cite{BevingtonRobinson200207}\cite{Conway:2011in} We assume that the number of events in each bin follows a Poisson distribution, defined as $P(n_{i}|\mu_{i}) = \frac{\mu_{i}^{n_{i}}e^{-\mu_{i}}}{n_{i}!}$, where $n_{i}$ is the number of events in the $i^{th}$ bin and $\mu_{i}$ is the number of Monte Carlo events in each bin. 

\qquad We then define the likelihood $L$ as $L =  \prod P(n_{i}|\mu_{i})$. The goal of the fit is to determine the $\mu_{i}$ that maximizes the likelihood. This procedure is complicated by the addition of the systematic uncertainties, which are treated as nuisance parameters. For example, the luminosity uncertainty introduces a  2.3\% uncertainty. To account for this, each term in the likelihood expression is multiplied by a log-normal distribution. The log-normal distribution is used instead of the Gaussian distribution to prevent the parameter from becoming negative. 
The lognormal distribution is defined: $N(\mu,\sigma) = \frac{1}{x\sigma \sqrt{2\pi}}e^{-\frac{(\log x - \mu)^{2}}{2\sigma^{2}}}$. 
Shape uncertainties, like the jet energy scale and tau energy scale systematics, are represented by Gaussian distributions. For the $j^{th}$ sample in the $i^{th}$ bin we can write: $\epsilon_{ji} = \epsilon_{ji}^{0} + f \frac{\epsilon_{ji}^{+} - \epsilon_{ji}^{-}}{2}$. Here, $\epsilon_{ji}^{0}$ is the efficiency before the shift, $\epsilon_{ji}^{+}$ is the efficiency after the scale shift up, and $\epsilon_{ji}^{-}$ is the efficiency after the scale shift down. 
The morphing parameter $f$ has a gaussian distribution. We can interpolate quadratically for $|f|<1$ and write $\epsilon_{ji} = \frac{f (f-1)}{2} \epsilon_{ji}^{-} - (f - 1)(f + 1)\epsilon_{ji}^{0}+\frac{f(f+1}{2}\epsilon_{ji}^{+}$ This term is then added as an additional factor in the maximum likelihood formula. 

\qquad The postfit histograms are shown in Figure \ref{fig:Mcol_Postfit}. %The postfit yields in the collinear mass signal region are given in tables *** and ***. The best fit on the lepton flavor violating signal gives us an expected branching ratio, shown in tables *** and ***. 
\subsection{Maximum Likelihood Limits}

\qquad After computing the expected LFV signal branching ratios, the next step is to determine the statistical significance of the result. The profile likelihood $\lambda(\mu)$ is defined as  $\lambda(\mu) = \frac{L(\mu,\hat{\hat{\theta)}}}{L(\hat{\mu},\hat{\theta})}$ where $\mu$ is the hypothesized signal strength defined by $\mu=0$ as the background hypothesis and $\mu=1$ the signal hypothesis.~\cite{Cowan:2010js} 
The nuisance parameters are represented by $\theta$. The denominator is the maximum value of the likelihood function, where $\hat{\mu}$ and $\hat{\theta}$ take their values that maximize the likelihood. The numerator is a likelihood as a function of $\mu$, where $\hat{\hat{\theta}}$ maximizes the likelihood for a given $\mu$. The profile likelihood can range between 0 and 1. 
We define our test statistic as $t_{\mu} = -2\ln\lambda\mu$. The probability distribution of this test statistic is given by $t_{\mu} = \frac{\mu-\hat{\mu}}{\sigma^2} + \mathcal{O}(\frac{1}{\sqrt{N}})$.~\cite{wald1943tests} 
Here $\sigma$ is related to the variance of all the nuisance parameters. We can make the asymptotic approximation that the second term goes to zero as $N \rightarrow \infty$. This is known as the asymptotic approximation.

\qquad Note that the test statistic is zero for total agreement between the hypothesis and the data and decreases as the data differs more and more from the hypothesis. The probability to observe a given hypothesis $\mu$ is defined by $p_{\mu} = \int_{\mu_{obs}}^{\infty} - 2 ln \lambda(\mu)$. The p-value is defined as $p_{\mu=0}$ and is the probability to exclude the background hypothesis. If $p<\alpha$ then we can consider the background hypothesis to be excluded. In high energy physics we define $\alpha$ as $2.87 \times 10^{-7}$. It is customary to express the in terms of standard deviations from the mean, assuming a Gaussian probability distribution function (PDF). For a p-value of $2.87 \times 10^{-7}$ the significance is 5$\sigma$. 

\qquad It is customary to use $95\%$ confidence intervals when setting limits. If $p_{\mu} < 5\%$ then the hypothesis where the signal strength is $\mu$ can be excluded at $95\%$ confidence. However, if the background is very small or fluctuates downward, it is possible to exclude a signal that the analysis is not sensitive to. This can be avoided by using the $CL_{s}$ method.~\cite{Read:451614} The p-value for the $CL_{s}$ method is defined by dividing the p-value for the signal hypothesis by the probability for excluding the background, which is $(1-p_{\mu=0})$.

\qquad It is useful to compare the observed limit with the expected limit. The expected limit is determined by generating an Asimov dataset~\cite{Cowan:2010js} which is consistent with the background hypothesis. By definition, the Asimov dataset will produce postfit nuisance parameters that are identical to their expected values. The expected limit is a useful statistic that measures the exclusion power of an analysis. For example, if the expected limit is significantly greater than the signal hypothesis, then the analysis does not have the statistical power to investigate the signal region. 
\section{Results}
\subsection{8 TeV Results}
The $M_\text{col}$ distributions after the fit for signal and background contributions are shown in Fig.~\ref{fig:Mcol_Postfit} and the
event yields in the mass range $100\:  < M_\text{col} < 150GeV$ are shown in Table~\ref{tab:EventYieldTable_100_to_150}.
The different channels and categories are combined  to set a $95\%$ $CL_{s}$  upper limit on the branching
fraction of LFV Higgs decay in the  $\mu \tau$ channel, $B(H\rightarrow\mu\tau)$.

\begin{figure*}[hbtp]\centering
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/muele_GG_m_colinear_UNBLIND_PostFit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/muhad_GG_m_colinear_UNBLIND_PostFit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/muele_Boost_m_colinear_UNBLIND_PostFit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/muhad_Boost_m_colinear_UNBLIND_PostFit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/muele_VBF_m_colinear_UNBLIND_PostFit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/muhad_VBF_m_colinear_UNBLIND_PostFit.pdf}
 \caption{Distributions of the collinear mass $M_\text{col}$ after fitting for signal and background  for the LFV $H \rightarrow \mu \tau$ candidates in
the different
channels and categories compared to data.
The distribution of the simulated LFV Higgs boson sample is shown for the best fit branching fraction
of $B(H \rightarrow \mu \tau )=0.84\%$.
The bottom panel in each plot shows the fractional difference between the observed data and the fitted background. Top left: $H \rightarrow \mu \tau_{e}$ 0-jet; top right: $H \rightarrow \mu \tau_{h}$ 0-jet;
middle left: $H \rightarrow \mu \tau_{e}$ 1-jet; middle right: $H \rightarrow \mu \tau_{h}$ 1-jet; bottom left: $H \rightarrow \mu \tau_{e}$ 2-jet; bottom right $H \rightarrow \mu \tau_{h}$ 2-jet.}
 \label{fig:Mcol_Postfit}\end{figure*}

\begin{table*}[hbtp]
 \centering
  \caption{Event yields in the signal region,  $100\: <  M_\text{col} < 150GeV $ after fitting for signal and background. The expected contributions are normalized to an integrated luminosity
of 19.7 $fb^{-1}$. The LFV Higgs boson signal is the expected yield for $B(H \rightarrow \mu \tau)=0.84\%$ with the SM Higgs boson cross section.}
  \label{tab:EventYieldTable_100_to_150}
  \begin{tabular}{lccc|ccc} \hline
        \multirow{2}{*}{Sample}                                & \multicolumn{3}{c}{$H \rightarrow \mu \tau_{h}$}                &     \multicolumn{3}{c}{$H \rightarrow \mu \tau_{e}$}     \\ \cline{2-7}
                                              &  0-Jet            & 1-Jet            & 2-Jets               &  0-Jet             & 1-Jet            & 2-Jets  \\ \hline
    misidentified leptons                          &  $  1770 \pm 530$      & $   377 \pm 114$      &  $     1.8 \pm   1.0$&  $    42 \pm  17$    &$    16 \pm   7$      & $     1.1 \pm   0.7$  \\
    $ Z \rightarrow \tau \tau$                        &  $   187 \pm   10$     & $    59 \pm   4$      &  $     0.4 \pm   0.2$&  $    65 \pm   3$    &$    39 \pm   2$      & $     1.3 \pm   0.2$   \\
    $ ZZ,WW$                                  &  $    46 \pm   8$      & $    15 \pm   3$      &  $     0.2 \pm   0.2$&  $    41 \pm   7$    &$    22 \pm   4$      & $     0.7 \pm   0.2$    \\
    $ W\gamma$                                &  NA  & NA  &  NA &  $     2 \pm   2$    &$     2 \pm   2$      & NA    \\
    $ Z \rightarrow ee$ or $\mu \mu$                  &  $   110 \pm  23$      & $    20 \pm   7$      &  $     0.1 \pm   0.1$&  $     1.6 \pm   0.7$&$     1.8 \pm   0.8$  & NA                  \\
    $t\bar{t}     $                      &  $     2.2 \pm   0.6$  & $    24 \pm   3$      &  $     0.9 \pm   0.5$&  $     4.8 \pm   0.7$&$    30 \pm   3$      & $     1.8 \pm   0.4$   \\
    $t\bar{t}   $                      &  $     2.2 \pm   1.1$  & $    13 \pm   3$      &  $     0.5 \pm   0.5$&  $     1.9 \pm   0.2$&$     6.8 \pm   0.8$  & $     0.2 \pm   0.1$   \\
    SM H background                       &  $     7.1 \pm   1.3$  & $     5.3 \pm   0.8$  &  $     1.6 \pm   0.5$&  $     1.9 \pm   0.3$&$     1.6 \pm   0.2$  & $     0.6 \pm   0.1$    \\
    sum of backgrounds                        &  $  2125 \pm 530$      & $   513 \pm 114$      &  $     5.4 \pm   1.4$&  $   160 \pm  19$    &$   118 \pm   9$     & $     5.6 \pm   0.9$    \\   \hline
    LFV Higgs boson signal                          &  $    66 \pm  18$      & $    30 \pm   8$      &  $     2.9 \pm   1.1$&  $    23 \pm   6$    &$    13 \pm   3$      & $     1.2 \pm   0.3$    \\   \hline
    data                                      &  $  2147 $             & $   511 $             &  $    10 $           &  $   180 $           &$   128 $             & $     6 $    \\   \hline
  \end{tabular}

\end{table*}

 The observed and the median expected $95\%$ $CL_{s}$ upper limits on the $B(H \rightarrow \mu \tau )$ for the H mass at 125 GeV are given for each category
 in Table~\ref{tab:expected_limits}.  Combining all
the channels, an expected upper limit of $B(H \rightarrow \mu \tau )<(0.75 \pm 0.38)\%$ is obtained. The
observed upper limit is $B(H \rightarrow \mu \tau ) < 1.51\%$ which is above the expected limit due to an excess of the
observed number of events above the background prediction.
The fit can then be used to estimate the branching fraction if this excess were to be interpreted as a signal.
The best fit values for the branching fractions are given in Table~\ref{tab:expected_limits}.
The limits and best fit branching fractions are also  summarized graphically  in
Fig.~\ref{fig:limits_summary}. The combined categories give a best fit of $B(H \rightarrow \mu \tau )=(0.84^{+0.39}_{-0.37})\%$. The combined excess is 2.4 standard deviations which corresponds to a  $p$-value of 0.010 at $M_{H}=125$ GeV.

\begin{table}[hbtp]
 \centering
  \caption{The expected upper limits, observed upper limits and best fit values for the branching fractions for different
    jet categories for the $H \rightarrow \mu \tau$  process.
    The one standard-deviation probability intervals around the expected limits are shown in parentheses.}
  \label{tab:expected_limits}
   \begin{tabular}{l|c|c|c} \hline
\multicolumn{4}{c}{Expected Limits} \\ \hline
                       &  \multicolumn{1}{c|}{0-Jet}   & \multicolumn{1}{c}{1-Jet}    &  \multicolumn{1}{|c}{2-Jets}                 \\
                       & (\%)                     & (\%)                     & (\%)                    \\ \cline{2-4}
          $\mu\tau_{e}$  &  $<$1.32 ($\pm$0.67)   &  $<$1.66 ($\pm$0.85)   &  $<$3.77 ($\pm$1.92)  \\
      $\mu\tau_{h}$    &  $<$2.34 ($\pm$1.19)   &  $<$2.07 ($\pm$1.06)   &  $<$2.31 ($\pm$1.18)  \\ \hline
            $\mu\tau$  &        \multicolumn{3}{c}{  $<$0.75 ($\pm$0.38 ) }                              \\ \hline
\multicolumn{4}{c}{Observed Limits} \\ \hline
          $\mu\tau_{e}$  &  $<$2.04                &  $<$2.38                &  $<$3.84   \\
      $\mu\tau_{h}$    &  $<$2.61                &  $<$2.22                &  $<$3.68   \\ \hline
            $\mu\tau$  & \multicolumn{3}{c}{  $<$1.51 }   \\ \hline
\multicolumn{4}{c}{Best Fit Branching Fractions} \\ \hline
      \rule[-5pt]{0pt}{17pt}
      $\mu\tau_{e}$  &  $0.87^{+0.66}_{-0.62}$  &  $0.81^{+0.85}_{-0.78}$  &  $0.05^{+1.58}_{-0.97}$  \\
      \rule[-5pt]{0pt}{17pt}
      $\mu\tau_{h}$    &  $0.41^{+1.20}_{-1.22}$  &  $0.21^{+1.03}_{-1.09}$  &  $1.48^{+1.16}_{-0.93}$  \\ \hline
      \rule[-5pt]{0pt}{17pt}
      $\mu\tau$  & \multicolumn{3}{c}{ $0.84^{+0.39}_{-0.37}$ }   \\ \hline
  \end{tabular}
\end{table}
\begin{figure*}[hbtp]\centering
\includegraphics[width=0.48\textwidth]{/home/aaron/root/hlfv/NewMETLimits.pdf}
 \caption{95\% CL Upper limits by category for the LFV $H \rightarrow \mu \tau$  decays.}
 \label{fig:limits_summary}\end{figure*}
 \subsubsection{Limits on lepton-flavour-violating couplings}
\begin{figure}[hbt]\centering
\includegraphics[width=0.49\textwidth]{yukawa.pdf}
 \caption{\cite{Khachatryan:2015kon}Constraints on the flavour-violating Yukawa couplings, $\abs{Y_{\mu\tau}}$ and $\abs{Y_{\tau\mu}}$.
The black dashed lines are contours of $B(H \rightarrow \mu \tau )$ for reference.
The expected limit (red solid line) with one sigma (green)  and two sigma (yellow) bands, and observed limit (black solid line) are derived from the limit on $B(H \rightarrow \mu \tau )$ from the present analysis.  The shaded regions are derived constraints from null searches for $\tau \rightarrow 3\mu$ (dark green) and $\tau \rightarrow \mu \gamma$ (lighter green). 
The yellow line is the limit from a theoretical reinterpretation of an ATLAS $H \rightarrow \tau \tau$ search~\cite{Harnik:2012pb}.
The light blue region indicates the additional parameter space excluded by our result.
The purple diagonal line is the theoretical naturalness
limit $Y_{ij}Y_{ji} \leq m_im_j/v^2$. }
 \label{fig:yukawalimits}\end{figure}

The constraint on $B(H \rightarrow \mu \tau )$ can be interpreted in terms of LFV  Yukawa couplings~\cite{Harnik:2012pb}.
The LFV decays $H \rightarrow e\mu$, $e\tau$, $\mu\tau$ arise at tree level from the assumed
flavour-violating Yukawa interactions, $Y_{\ell^{\alpha}\ell^{\beta}}$ where $\ell^{\alpha},\ell^{\beta}$ denote the leptons, $\ell^{\alpha},\ell^{\beta}=e,\mu,\tau$ and $\ell^{\alpha}\neq \ell^{\beta}$.
The decay width $\Gamma(H \rightarrow \ell^{\alpha}\ell^{\beta})$  in terms of the Yukawa couplings is given by:
\begin{equation*}
\Gamma(H \rightarrow \ell^{\alpha}\ell^{\beta})=\frac{m_{H}}{8\pi}\bigl(\abs{Y_{\ell^{\beta}\ell^{\alpha}}}^2 + \abs{Y_{\ell^{\alpha}\ell^{\beta}}}^2\bigr),
\end{equation*}
and the branching fraction by:
\begin{equation*}
B(H \rightarrow \ell^{\alpha}\ell^{\beta})=\frac{\Gamma(H\rightarrow \ell^{\alpha}\ell^{\beta})}{\Gamma(H\rightarrow \ell^{\alpha}\ell^{\beta}) + \Gamma_{SM}}.
\end{equation*}
The SM H decay width is assumed to be $\Gamma_{SM}=4.1$MeV~\cite{Denner:2011mq} for $M_{H}$=125GeV.
The 95\% CL constraint on the Yukawa couplings derived from $B(H \rightarrow \mu \tau )<1.51\%$ and the expression for the branching fraction above is:\begin{equation*}
\sqrt{\abs{Y_{\mu\tau}}^{2}+\abs{Y_{\tau\mu}}^{2}}<3.6\times 10^{-3}.
\end{equation*}
Figure~\ref{fig:yukawa} compares this result to the constraints from previous indirect
measurements.
\subsection{13 TeV Results}
After applying the full selection cuts, a maximum likelihood fit is performed in the $M_\text{col}$ variable. Each systematic uncertainty is used as a nuisance parameter in the fit. The distributions of the signal and background contributions after the full selection and the fit are shown in Fig.~\ref{fig:Mcol_SignalRegion13TeV} and the
event yields in the mass range $100\:  < M_\text{col} < 150GeV$ are shown in Table~\ref{tab:EventYieldTable_100_to_150_13TeV}.
The different channels and categories are combined  to set a $95\%$ CL  upper limit on the branching
fraction of LFV H decay in the  $\mu\tau$ channel, $V(H\rightarrow\mu\tau)$.

\begin{figure*}[hbtp]\centering
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V6_MuonFix_SystematicsFix/LFVMuE_SR_OS_0Jet_UnBlinded_Postfit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V6_MuonFix_SystematicsFix/LFVMuTau_SR_OS_0Jet_UnBlinded_Postfit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V6_MuonFix_SystematicsFix/LFVMuE_SR_OS_1Jet_UnBlinded_Postfit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V6_MuonFix_SystematicsFix/LFVMuTau_SR_OS_1Jet_UnBlinded_Postfit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V6_MuonFix_SystematicsFix/LFVMuE_SR_OS_2Jet_UnBlinded_Postfit.pdf}
 \includegraphics[width=0.48\textwidth]{/home/aaron/root/lfv/76X_V6_MuonFix_SystematicsFix/LFVMuTau_SR_OS_2Jet_UnBlinded_Postfit.pdf}
\caption{Distributions of the collinear mass $M_\text{col}$ after fitting for signal and background at $\sqrt{s}$ = 13 TeV for the LFV $H \rightarrow \mu \tau$ candidates in
the different
channels and categories compared to data.
The distribution of the simulated LFV Higgs boson sample is shown for $B(H \rightarrow \mu \tau )=10\%$.
The bottom panel in each plot shows the fractional difference between the observed data and the fitted background. Top left: $H \rightarrow \mu \tau_{e}$ 0-jet; top right: $H \rightarrow \mu \tau_{h}$ 0-jet;
middle left: $H \rightarrow \mu \tau_{e}$ 1-jet; middle right: $H \rightarrow \mu \tau_{h}$ 1-jet; bottom left: $H \rightarrow \mu \tau_{e}$ 2-jet;
bottom right $H \rightarrow \mu \tau_{h}$ 2-jet.}
 \label{fig:Mcol_SignalRegion13TeV}\end{figure*}
 
 \begin{table*}[hbtp]
 \centering  \caption{Event yields in the signal region in the range $100 < M_\text{col} < 150GeV$ . The expected contributions are normalized to an integrated luminosity
of 2.3$fb^{-1}$. The LFV Higgs boson signal is the expected yield for $B(H \rightarrow \mu \tau)=1\%$ with the SM Higgs boson cross section.}
  \label{tab:EventYieldTable_100_to_150_13TeV}
%   \cmsTable{\textwidth}{
  \begin{tabular}{lccc|ccc} \hline
        \multirow{2}{*}{Sample}                                & \multicolumn{3}{c}{$H \rightarrow \mu \tau_{e}$}                &     \multicolumn{3}{c}{$H \rightarrow \mu \tau_{h}$}     \\ \cline{2-7}
                                              &  0-Jet            & 1-Jet            & 2-Jets               &  0-Jet             & 1-Jet            & 2-Jets  \\ \hline
    misidentified leptons                    &  12.2  &   5.2     &  2.8 & 232.3 & 54.7 & 4.7 \\
    $ Z \rightarrow \tau \tau$                    & 14.4   & 10.6      &  1.7 & 5.3   & 2.3  & 0  \\
    $ ZZ,WW$                       & 10.7   &  4.6      &  3.2 & 3.2   & 2.0  & 0.3\\
    $ W\gamma$                             &   1.2  &  3.4      &  0.9 &NA & NA & NA    \\
    $ Z \rightarrow ee$ or $\mu \mu$          &  1.9   &  2.2      &  0.3 & 79.1 & 11.9& 0.1  \\
    $t\bar{t}     $                            &  1.4   & 21.8      & 18.6 &1.3 & 5.4 & 1.1    \\
    t, $\bar{t}$                             &  0.4   &  4.1      &  1.7 &0.3 & 2.2 & 0.2    \\
    SM H background                        &  0.4   &  0.4      &  0.4 &1.1 & 0.7 & 0.3    \\ \hline
    sum of backgrounds                       & 42.6   & 52.2      & 29.6 &322.5& 79.3 & 6.6  \\  \hline
    LFV Higgs boson signal                   &  7.1   &  3.7      &  1.9 &13.8 & 4.7 & 1.2    \\ \hline \hline
      Observed data                          &  33    &  41       &  31  & 315 & 77 & 7 \\ \hline
  \end{tabular}
%  }
\end{table*}


\subsection{Limit computation}

The observed and median expected $95\%$ CL upper limits on the $B(H \rightarrow \mu \tau )$ for the H mass at 125GeV are given for each category
in Table~\ref{tab:expected_limits13TeV}.  Combining all
the channels, an expected upper limit of $B(H \rightarrow \mu \tau )<(1.62 \pm 0.58)\%$ is obtained.
The observed upper limit is $B(H \rightarrow \mu \tau ) < 1.20\%$.
The limits are also  summarized graphically  in
Fig.~\ref{fig:limits_summary}.

This observed limit on the branching ratio is slightly tighter than the $B(H \rightarrow \mu \tau )<(1.51 \pm 0.83)\%$ limit obtained using the 19.7 $fb^{-1}$ data sample at 8 TeV analyzed in~\cite{Khachatryan:2015kon}. The 95\% CL constraint on the Yukawa couplings derived from $B(H \rightarrow \mu \tau )<1.20\%$ and the expression for the branching fraction above is:\begin{equation*}
\sqrt{\abs{Y_{\mu\tau}}^{2}+\abs{Y_{\tau\mu}}^{2}}<3.16\times 10^{-3}.
\end{equation*}

\begin{table}[hbtp]
 \centering
  \caption{The observed and expected upper limits for different
    jet categories for the $H \rightarrow \mu \tau$  process.
    The one standard deviation probability intervals around the expected limits are shown in parentheses.}
 \label{tab:expected_limits13TeV}
\begin{tabular}{c|c|c|c|c} \hline
\multicolumn{5}{c}{Expected limits} \\ \hline
                       &  \multicolumn{1}{c|}{0-jet}   & \multicolumn{1}{c|}{1-jet}    &  \multicolumn{1}{c|}{2-jets} & \multicolumn{1}{c}{Combined}                 \\
                       & (\%)                     & (\%)                     & (\%)  &    (\%)                  \\   \cline{2-5}
          $\mu\tau_{h}$  & $<$4.17  & $<$4.89   & $<$6.41   &   $<$2.98   \\
      $\mu\tau_{e}$           & $<$2.24   &  $<$4.36  &  $<$7.31  &  $<$1.96    \\ \hline
            $\mu\tau$      &        \multicolumn{4}{c}{  $<$1.62  \% }                              \\ \hline \hline
\multicolumn{5}{c}{Observed limits} \\ \hline
                       &  \multicolumn{1}{c|}{0-jet}   & \multicolumn{1}{c|}{1-jet}    &  \multicolumn{1}{c|}{2-jets} & \multicolumn{1}{c}{Combined}                 \\
                       & (\%)                     & (\%)                     & (\%)  &    (\%)                  \\   \cline{2-5}
          $\mu\tau_{h}$  & $<$4.24  & $<$6.35   & $<$7.71   &   $<$3.81   \\
      $\mu\tau_{e}$           & $<$1.33   &  $<$3.04  &  $<$8.99  &  $<$1.15    \\ \hline
            $\mu\tau$      &        \multicolumn{4}{c}{  $<$1.20  \% }                              \\ \hline \hline
\multicolumn{5}{c}{Best fit branching fractions} \\ \hline
                       &  \multicolumn{1}{c|}{0-jet}   & \multicolumn{1}{c|}{1-jet}    &  \multicolumn{1}{c|}{2-jets} & \multicolumn{1}{c}{Combined}                 \\
                       & (\%)                     & (\%)                     & (\%)  &    (\%)                  \\   \cline{2-5}
      \rule[-5pt]{0pt}{17pt}
      $\mu\tau_{h}$  &  $0.12^{+2.02}_{-1.91}$  &  $1.70^{+2.41}_{-2.52}$  &  $1.54^{+3.12}_{-2.71}$  &   $1.12^{+1.45}_{-1.40}$   \\
      \rule[-5pt]{0pt}{17pt}
      $\mu\tau_{e}$    &  $-2.11^{+1.30}_{-1.89}$  &  $-2.18^{+1.99}_{-2.05}$  &  $2.04^{+2.96}_{-3.31}$ & $-1.81_{-1.32}^{+1.07}$  \\ \hline
      \rule[-5pt]{0pt}{17pt}
      $\mu\tau$  & \multicolumn{4}{c}{ $-0.76^{+0.81}_{-0.84}$\% }   \\ \hline
  \end{tabular}
\end{table}


\begin{figure*}[hbtp]\centering
\includegraphics[width=0.48\textwidth]{13TeVLimits.pdf}
 \caption{95\% CL Upper limits by category for the LFV $H \rightarrow \mu \tau$  decays.}
 \label{fig:limits_summary13TeV}\end{figure*}



\chapter{W+Jets Differential Cross Section Measurement}\label{wjets}
\section{Backgrounds and Datasets}
\subsection{Data}
\qquad This measurement utilizes data collected at $\sqrt{s}$ = 13 TeV in 2015 at the LHC. The trigger selection requires an isolated single muon with $p_{T} >$ 20 GeV in the range $|\eta| < 2.4$. The integrated luminosity used is 2.5$fb^{-1}$. This is 0.2 $fb^{-1}$ more than the 13 TeV LFV dataset. The reason for this discrepancy is that LFV events must come from a time period in which the forward hadronic calorimeter is certified to be working correctly. The jet pull in VBF Higgs events requires the use of the forward calorimeter system to identify high $|\eta|$ jets, but this requirement is not necessary for a W+jets measurement.

\subsection{Monte Carlo}
\qquad Background processes with similar final state signatures as W+jets are Z+jets, $t\bar{t}$, single top, diboson +jets, and QCD multijets. The QCD multijet background is estimated using a data-driven method, as discussed in section \ref{qcdestimate}. The other backgrounds are all estimated using Monte Carlo. W+jets and Z+jets samples are generated with \textsc{{\sc MadGraph5$\_$aMC@NLO}}. 
The $t\bar{t}$ background is generated using POWHEG. Single top backgrounds are generated using {\sc MadGraph5$\_$aMC@NLO} or POWHEG, depending on the channel. 
%The tW single top channel is generated with POWHEG, but the s and t channels are generated with
The single top simulation is generated with a mixture of POWHEG and {\sc MadGraph5$\_$aMC@NLO}, depending on the decay channel. Dibison simulation is generated using POWHEG for WW and PYTHIA8 for WZ and ZZ. The CUETP8M1\cite{Khachatryan:2015pea} tune scenario is used in PYTHIA8 for parton showering and hadronization. MCFM is used the evaluate the Monte Carlo cross sections at NLO. 

\qquad The experimentally measured W+jets differential cross sections are compared to two matrix element calculations. The leading order calculation is generated by MADGRAPH5 interfaced with PYTHIA8 for parton showering and hadronization. The CTEQ6L1 parton distribution functions are used \cite{Manohar:2012pe}, and the matrix element calculation is matched to the parton showering using the MLM scheme \cite{Alwall:2008qv}\cite{Alwall:2007fs} The MLM matching algorithm is as follows. After parton showering in pythia, as described in section \ref{mcgen}, the anti-$k_{t}$ jet cone algorithm is applied to the showered partons. The jet closest in $(\eta, \phi)$ to the hardest parton is selected. If the distance between the jet and the parton is less than 1.5 times the cone of radius R used in the jet clustering algorithm, then the jet and the parton are matched. Each hard parton must be matched to a jet. If a hard parton in an event is not matched to a jet, then the event is rejected. The NLO calculation is computed with {\sc MadGraph5$\_$aMC@NLO} interfaced with PYTHIA8 in the CUETP8M1 tune. The FXFX merging scheme \cite{Frederix:2012ps} is used with a merging scale parameter of 30 GeV. The NNPDF 3.0 NLO PDF \cite{Ball:2014uwa} is used for the matrix element calculation, while the NNPDF 2.3 LO \cite{Ball:2010de}\cite{Ball:2011mu} is used for the parton showering and hadronization. This gives NLO accuracy for 0,1, and 2 jet events and LO accuracy for 3 and 4 jet events. 

\subsection{QCD Background}\label{qcdestimate}

\qquad The QCD background is estimated using a data driven method. Four regions are defined. Region A, the signal region, requires an isolated muon and a $M_{T} >$ 50 GeV cut. Region B requires an isolated muon and a $M_{T} <$ 50 GeV, minimizing the W+Jets contribution. Regions C and D are analogous to regions A and B, but with an inverted muon isolation requirement, which maximizes the QCD contribution.

\qquad In region A, the W+jets Monte Carlo is scaled by a factor $f_{W}$ such that the number of W+jets and background Monte Carlo events exactly matches the number of data events in region A. This same scale factor is applied to W+jets in regions B,C, and D as well.

\qquad In region C, a histogram that determines the QCD shape is created by subtracting the Monte Carlo histograms from the data histograms. 

\qquad The muon isolation fake rate $f_{B/D}$ is calculated by dividing the difference between the data and Monte Carlo event counts in region B by the difference between the data and Monte Carlo event counts in region D. This fake rate factor is applied to the QCD histogram in region C to give a QCD estimate in the signal region. 

\qquad However, the scale factor for W+jets computed in region A at the beginning of the procedure did not take the QCD background into account. The calculation is repeated 11 additional times, at which point $f_{W}$ and $f_{B/D}$ will have stabilized.
 
\section{Event Selection}
\qquad As mentioned in section \ref{wboson}, W bosons decay to hadrons or leptons. This analysis focuses on the muonic decay channel, where the W boson decays to a muon and its associated neutrino. The muon system of CMS, as discussed in section \ref{muonsys}, enables particularly high muon efficiency and accurate energy resolution. Complicated scenarios such as hadronic tau decays or superclusters of e/$\gamma$ deposits are avoided by choosing the muonic channel. Muons are required to have $p_{T}$ > 25 GeV, $|\eta| <$ 2.4, and $I_{PF}^{\mu} < 0.15$. Jets are identified using the anti-$k_{T}$ algorithm (section \ref{jets}), with $p_{T} >$ 30 GeV and $|y| <$ 2.4. Jets are required to be separated by $\Delta R >$ 0.4 from muon candidates. Jets that originate from pileup interactions, rather than the hard scattering event that produces the W boson, are referred to as pileup jets. The contamination from pileup jets is reduced by requiring jets to originate from the same vertex as the muon candidate. This is accomplished by passing vertex and jet shower shape variables into a boosted decision tree which returns a discriminator for pileup jets \cite{CMS-PAS-JME-13-005}. An additional cut is placed on the discriminator so that W+jets events exhibit a minimal dependence on the pileup.

\qquad The main background to W+jets production at high jet multiplicities is $t\bar{t}$ production. The top quarks will decay into their lighter partners, bottom quarks, which will produce b jets. The $t\bar{t}$ contamination is reduced by applying a b-jet veto, as discussed in section \ref{jets}. The yield differences between table \ref{tab:btag} and table \ref{tab:events} show the effect of the b-jet veto. At high jet multiplicities the $t\bar{t}$ contribution is reduced by approximately a factor of six while the $W \rightarrow \mu\nu$ signal remains at 80\%-90\% of its pre-veto yield.

\begin{table}\small
\centering
\caption{Number of events in data and simulation as a function of the exclusive jet multiplicity before the implementation of b tag veto. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\footnotesize{
\begin{tabular}{l|ccccccc}
  &  $N_{\text{jets}} = 0 $ & $N_{\text{jets}} = 1 $ & $N_{\text{jets}} = 2 $ & $N_{\text{jets}} = 3 $ & $N_{\text{jets}} = 4 $ & $N_{\text{jets}} = 5 $ & $N_{\text{jets}} = 6 $ \\ \hline
   VV        & 4041 & 3122 & 1336 & 382 & 92 & 19 & 3  \\
   QCD        & 411822 & 109220 & 23304 & 4343 & 639 & 126 & 0  \\
   Single top        & 4341 & 13379 & 11519 & 5437 & 1956 & 612 & 176 \\
   DYJets        & 624220 & 94046 & 21916 & 4805 & 1036 & 209 & 59 \\
   $t\bar{t}$        & 1951 & 12400 & 34151 & 46371 & 31871 & 13838 & 5147 \\
   $\PW \rightarrow \mu\nu$        & 14401433 & 2004189 & 433512 & 84961 & 16012 & 3438 & 369 \\
 \hline
 TOTAL & 15447808 & 2236356 & 525738 & 146299 & 51606 & 18242 & 5754 \\
 \hline
 Data          & 16105074 & 2204919 & 526117 & 153912 & 55339 & 18580 & 5483 \\
  %Ratio          & 0.959189 & 1.014258 & 0.999280 & 0.950537 & 0.932543 & 0.981808 & 1.049425 \\ 
 \end{tabular}}
\label{tab:btag}
\end{table}

\begin{table}\small
\centering
\caption{Number of events in data and simulation as a function of the exclusive jet multiplicity after the implementation of b tag veto. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\footnotesize{
\begin{tabular}{l|cccccccc}
  &  $N_{\text{jets}} = 0 $ & $N_{\text{jets}} = 1 $ & $N_{\text{jets}} = 2 $ & $N_{\text{jets}} = 3 $ & $N_{\text{jets}} = 4 $ & $N_{\text{jets}} = 5 $ & $N_{\text{jets}} = 6 $ \\ \hline
   VV        & 3961 & 2917 & 1189 & 325 & 76 & 15 & 2 \\
   QCD        & 393632 & 94835 & 18662 & 3526 & 465 & 263 & 0 \\
   Single top        & 3426 & 6850 & 4747 & 1884 & 558 & 145 & 38 \\
   DYJets        & 617130 & 89398 & 19782 & 4278 & 887 & 180 & 45 \\
   $t\bar{t}$         & 1323 & 5178 & 9765 & 9989 & 5850 & 2332 & 825 \\
   $\PW \rightarrow \mu\nu$        & 14250375 & 1914920 & 400201 & 76319 & 13153 & 2995 & 310 \\
 \hline
 TOTAL & 15269847 & 2114098 & 454346 & 96321 & 20989 & 5930 & 1220 \\
 \hline
 Data          & 15962756 & 2096555 & 454919 & 101282 & 24903 & 6319 & 1515 \\
  %Ratio          & 0.956592 & 1.008368 & 0.998740 & 0.951018 & 0.842830 & 0.938440 & 0.805281 \\ 
 \end{tabular}}
 \label{tab:events}
 \end{table}

\qquad Events are vetoed if they contain additional muons with $p_{T} >$ 15 GeV and $|\eta| <$ 2.4. The transverse mass ($M_{T}$) between the muon and the missing transverse energy is defined as $M_{T}(\mu,E_{T}^{miss}) = \sqrt{2 p_{T}^{\mu} E_{T}^{miss} (1-cos\Delta\phi)}$, where $\Delta\phi$ is the difference in azimuthal angle between the muon momentum and the $\vec{E}_{T}^{miss}$ vector. In W+jets events the muon and the neutrino tend to be emitted back-to-back, which maximizes $M_{T}$ with respect to $\Delta\phi$. Events are required to be in the W transverse mass peak region, which is defined by $M_{T} >$ 50 GeV.

\section{Data-Simulation Comparisons}
\qquad After applying selections, the data and simulation agreement is compared for several kinematic observables. These are show in figures \ref{mult} through \ref{eta34}.

\qquad The event yields for data and simulation processes in each bin of exclusive jet multiplicity are listed in Table \ref{tab:events}.

\qquad At high jet multiplicites, the W+jets signal is less dominant and the accuracy of the largest background, $t\bar{t}$, becomes more important. A $t\bar{t}$ enriched control sample was created by removing the b-jet veto and requiring two or more b-tagged jets. The data-simulation agreement was found to be with 10\% up to the exclusive jet multiplicity of 5 and the inclusive jet multiplicity of 4. 

\begin{figure}[!Hhtbp]
%\renewcommand{\figurename}{Figure}
\begin{center}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/ZNGoodJets_Zexc.pdf}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/ZNGoodJets_Zinc.pdf}
\end{center}
\caption{Data to simulation comparison of exclusive (left) and inclusive (right) jet multiplicity. QCD background is estimated using a data-driven method. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\label{mult}
\end{figure}

\begin{figure}[!Hhtbp]
%\renewcommand{\figurename}{Figure}
\begin{center}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/FirstJetPt_Zinc1jet.pdf}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/SecondJetPt_Zinc2jet.pdf}\\
\end{center}
\caption{Data to simulation comparison of $1^{st}$ (left) and $2^{nd}$ (right) jet $p_{T}$. QCD background is estimated using a data-driven method. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\label{pt12}
\end{figure}

\begin{figure}[!Hhtbp]
%\renewcommand{\figurename}{Figure}
\begin{center}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/ThirdJetPt_Zinc3jet.pdf}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/FourthJetPt_Zinc4jet.pdf}
\end{center}
%\caption{Data to simulation comparison for $3^{rd}$ jet $p_{T}$.}
\caption{Data to simulation comparison of $3^{rd}$ (left) and $4^{th}$ jet $p_{T}$. QCD background is estimated using a data-driven method. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\label{pt34}
\end{figure}

\begin{figure}[!Hhtbp]
%\renewcommand{\figurename}{Figure}
\begin{center}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/FirstJetAbsRapidity_Zinc1jet.pdf}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/SecondJetAbsRapidity_Zinc2jet.pdf}
\end{center}
\caption{Data to simulation comparison of $1^{st}$ (left) and $2^{nd}$ jet $|y|$. QCD background is estimated using a data-driven method. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\label{eta12}
\end{figure}

\begin{figure}[!Hhtbp]
%\renewcommand{\figurename}{Figure}
\begin{center}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/ThirdJetAbsRapidity_Zinc3jet.pdf}
\includegraphics[width=0.45\textwidth]{/home/aaron/root/wjets/June12_WJetsFinal/FourthJetAbsRapidity_Zinc4jet.pdf}
\end{center}
%\caption{Data to simulation comparison for $3^{rd}$ jet $y$.}
\caption{Data to simulation comparison of $3^{rd}$ (left) and $4^{th}$ jet $|y|$. QCD background is estimated using a data-driven method. The diboson samples (WW, WZ, and ZZ) are represented by VV.}
\label{eta34}
\end{figure}


\section{Detector Unfolding}
\qquad The CMS detector, like any experimental instrument, is not infallible. The detector response can cause a measurement to deviate from its true value. For example, for a given event with a leading jet $p_{T}$ in the 40-45 GeV bin, there is a probability that the jet could have had a $p_{T}$ in the 35-40 GeV bin or in the 45-50 GeV bin. The detector response can cause the measured value to deviate from its true value. A response matrix is used to transform the measured values to the true values. 

\qquad A Bayesian unfolding method~\cite{D'Agostini:1995487} is used for W+Jets. The $i^{th}$ generated event $Gen_{i}$ results in a measured event $Reco_{i}$. The probability of a generated event to be observed in the $i^{th}$ bin is $P(Gen_{i})$. The probability that a reco event in bin $j$ is due to a generated event in bin $i$ is $P(Reco|Gen_{i})$. From those relations, Bayes' theorem~\cite{BevingtonRobinson200207} is used to obtain $P(Gen_{i}|Reco_{j}) = \frac{P(Reco_{j}|Gen_{i})P(Gen_{i})}{\Sigma_{l=1}^{n_{bins}}P(Reco_{j}|Gen_{l})P(Gen_{l})}$

\qquad The probability to observe a reconstructed event in bin $j$ given an generator level event in bin $i$ is given by $P(Reco_{j}|Gen_{i})$. This probability is represented by a matrix, defined as the response matrix ($R_{ji}$). The response matrix is calculated by using Monte Carlo (Section 4) to compare generator level events to events reconstructed with detector simulation. It can be visualized for a particular variable by plotting the number of generator level events versus the number of reco level events. After calculating the response matrix, Bayes' theorem is used to obtain the probability that a reconstructed event in bin $j$ was due to a generator level event in bin $i$. This probability distribution, $P(Gen_{i}|Reco_{j})$, is referred to as the smearing matrix, $S_{ij}$.

\qquad The number of true events observed in bin $i$ is defined as $\hat{n}(i) = \frac{1}{\epsilon_{i}}\Sigma_{j=1}^{n_{bins}}n_{obs}(j)S_{ij}$, where $\epsilon_{i}$ is the efficiency of observing an event that was generated in bin $i$ and is defined by $\epsilon_{i}=\Sigma_{j=1}^{n_bins}R_{ji}$.

\qquad Given the above formulas, the number of true events in each bin can be calculated. The only unknown quantity is $P(Gen_{i})$, the probability to observe a generator level event in bin $i$. This probability is determined by an iterative $\chi^2$ fit. First, $P(Gen_{i})$ is estimated from the Monte Carlo distribution. This allows a simple estimation of the true number of events: $\hat{n}_{0} = P(Gen_{i})N_{obs}$, where $N_{obs}$ is the total number of observed events. Then use Bayes' Theorem to calculate $\hat{n}(i)$ and $\hat{P}(Gen_{i})$. The third step is to calculate the $\chi^{2}$ distribution between $\hat{n}(i)$ and $\hat{n}_{0}(i)$. The iterative procedure is then repeated, with $\hat{n}(i)$ and $\hat{P}(Gen_{i})$ used in the first step. The iterative procedure is repeated at least four times and is concluded when $\chi^{2}/\nu < \frac{1}{\sqrt{2}}$.

\qquad In the generator level simulation, the events are required to pass the same event selection used in the reconstruction level, including the requirements on muon $p_{T}$ and $|\eta|$, jet $p_{T}$ and $|y|$, and $M_{T}$. The generator level jets are built in the same way as the reconstructed jets, via the the anti-$k_{T}$ algorithm. The generator level muons are "dressed" by recombining the bare generator level muons with all of the radiated photons within a cone of radius 0.1 to accout for final state radiation. The $M_{T}$ of the the W Boson is calculated using the dressed muon and the neutrino. The response object is then constructed from the response matrix, the reconstructed level distribution, and the corresponding generator level distribution. 

\section{Systematic Uncertainties}

\qquad The dominant source of systematic uncertainty is the jet energy scale uncertainty. This uncertainty is equal to 1.4\% for a jet multiplicity of 1 and increases with the number of reconstructed jets. Uncertainties in the jet energy scale are propagated to the calculation of $E_{T}^{miss}$.

\qquad The background cross sections are varied within their theoretical uncertainties. The cross section of $t\bar{t}$, which is the largest background contribution, is varied by 10\%. The additional backgrounds are simultaneously varied up and down by 7\% (ZZ, WZ), 6\% (WW and tW single top), and 4\% (Z+jets, s and t-channel single top). 

\qquad A systematic uncertainty associated with the generator used to build the unfolding response matrix is computed by weighting the simulation to agree with the data in $p_{T}$, $|y|$, and $H_{T}$ distributions, and then building a reweighted response to unfold the data. The difference between the nominal results and the results unfolded using the reweighted response matrix is taken as the systematic uncertainty associated with the unfolding response matrix.

\qquad A systematic uncertainty associated with the jet energy resolution (JER) scale factors is computed by varying the scale factors up and down by 1$\sigma$. The resulting uncertainty is on the order of 1\%.

\qquad The uncertainty in the pileup modeling is computed by varying the inelastic proton-proton cross section within its uncertainty of $\pm 5\%$. The resulting uncertainty is on the order of 1\%.

\qquad The data-to-simulation correction factors of the b tagging efficiencies are varied up and down by $1 \sigma$. The entire analysis is performed with these variations and the final unfolded results are compared to the results of the unshifted analysis. The effect on the measured cross section varies between 0.4\%-11\% depending on the jet multiplicity as shown in table \ref{tab:DMuZNGoodJets_Zexc}.

\qquad The uncertainties of the muon trigger, identification, and isolation efficiencies are summed in quadrature to give an overall systematic uncertainty on the data-to-simulation muon scale factors. The uncertainty is computed to be 1.23\%.

\qquad The uncertainty on the integrated luminosity measurement is estimated as 4.6\%.

\subsection{Theoretical Uncertainties}
\qquad As shown in figure \ref{fig:xsec_Njets_nlo}, the measured W+Jets cross section is compared to the results from the {\sc MadGraph5$\_$aMC@NLO} FXFX event generator. The shaded blue band corresponding to the theoretical uncertainties on the {\sc MadGraph5$\_$aMC@NLO} FXFX event generator is computed as described below.

\qquad The factorization ($\mu_{f}$) and renormalization scales ($\mu_{r}$) in QCD control the cut-offs for infrared divergences and ultraviolet divergences. By varying these scales in Monte Carlo and measuring the shifts in event acceptance, systematic uncertainties for W+Jets production can be obtained.

\qquad These scales affect QCD radiation, which will effect parton showering and jet creation. Therefore, the effects of varying these scales are jet bin dependant. However, we cannot simply vary the scales in exclusive jet bins because the uncertainties will be underestimated~\cite{Gangal:2013nxa}~\cite{Stewart:2011cf} To properly calculate uncertainties in exclusive jet bins, the exclusive uncertainties must be defined in terms of the inclusive uncertainties.
This is accomplished by defining the exclusive cross section in terms of inclusive cross sections: $\sigma_{N} = \sigma_{\geq N} - \sigma_{\geq N+1}$

\qquad The uncertainty in the exclusive cross section is then calculated by adding the inclusive cross section uncertainties in equation~\eqref{eq:excunc}.

\begin{equation}
\label{eq:excunc}
\Delta_{N}^2 = \Delta_{\geq N}^2 + \Delta_{\geq N+1}^2
\end{equation}

\subsection{Methodology}
\label{application}

\qquad The analysis cuts are applied at generator level in the W+Jets {\sc MadGraph5$\_$aMC@NLO} sample. The muon is required to have originated from a W boson decay. Jets are required to have $p_{T} > 30$ and $|\eta| < 2.4$. Muons are required to have $p_{T} > 25$ GeV and $|\eta| < 2.4$. An $M_{T}$ cut of the form $M_{T}(\mu,E_{T}^{miss}) > 50$ GeV is applied, and the muon and the jet are required to be separated by $\Delta R(\mu,jet) > 0.4$. Starting from a default value of $\mu_{r} = \mu_{f} = 1$, the scales are varied by a factor of two. The theoretical uncertainty, which is defined in terms of event acceptance, is equal to $\frac{|A_{\mu=2} - A_{\mu=1/2}|}{2 \times A_{\mu=1}}$  The results are in Table~\ref{tab:JetUncTable}. Note that adding the inclusive uncertainties in quadrature increases the uncertainty, especially in the zero jets bin.

\qquad Note that in Figure~\ref{fig:acceptances} the exclusive acceptance difference in the first bin ($N_{jets}=0$) is much smaller than the acceptance differences in the neighboring inclusive bins of $N_{jets} \geq 0$ and $N_{jets} \geq 1$, which represent the uncertainties at the boundaries of the $N_{jets}=0$ region. The seemingly small uncertainty in the $N_{jets}=0$ region is not in fact caused by small changes within the region but by cancellation of large migrations of events into and out of the region. A smaller version of this effect can be seen in all of the other exclusive jet bins.
It is therefore justified to quantify the theoretical uncertainty of an exclusive jet bin by the migrations of events into and out of the bin, rather than the absolute change of the number of events in the jet bin. The uncertainties at the boundaries of the jet bin are represented by the inclusive uncertainties, which leads us to equation.



\begin{table*}[hbtp]
 \centering  
 \caption{Comparison of exclusive uncertainties in jet bins. The direct scale variation method means that the uncertainties have been computed by observing the difference in yields after varying $\mu_{r}$ and $\mu_{f}$. The via inclusive method adds the inclusive uncertainties according to ~\ref{eq:excunc}.}
  \label{tab:JetUncTable}
   
  \begin{tabular}{l|c|c|c} \hline
    $N_{jets} =$       &Inclusive(\%)   &  Direct Scale (\%)    & Via Inclusive (\%) \\ \hline
    0                  & 0.1   & 1.1  & 6.2 \\
    1                  & 6.2   & 5.5  & 10.8\\
    2                  & 8.9   & 8.2  & 14.7\\
    3                  & 11.8  & 11.7 & 16.8\\
    4                  & 11.9  & 10.9 & 19.5\\
    5                  & 15.5  & 16.4 & 19.8\\
    6                  & 12.3  & 9.9  & 23.7\\
    7                  & 20.3  & 19.2 & 30.6\\
  \hline
  \end{tabular}
  
\end{table*}

\begin{figure}[hbt]\centering
\includegraphics[width=0.49\textwidth]{energyScalesWJets.pdf}
 \centering 
 \caption{Changes in acceptance for inclusive and exclusive jets, as a function of number of jets. The points in the middle of the bins are the exclusive variations and the points at the edges of the bins are the inclusive variations. The inclusive variations show the changes in acceptance at the boundaries of the exclusive jet bins.}
 \label{fig:acceptances}\end{figure}
 
\section{Results}
\qquad The cross sections of jet multiplicities are measured up to 5 jets. The measured W+jets differential cross section distributions are compared with the predictions of the {\sc MadGraph5$\_$aMC@NLO} FXFX and MADGRAPH5 LO MLM event generators. As shown in figure \ref{fig:xsec_Njets_nlo}, the measured data and predictions are generally agreement within uncertainties. MADGRAPH5 appears to underestimate the measured cross section up to a multiplicity of 4. Tables \ref{tab:DMuZNGoodJets_Zexc} and \ref{tab:SMuZNGoodJetsFull_Zinc} show the measured cross sections and associated uncertainties.


\begin{table}[!Hhtbp]
\begin{center}
\caption{Differential cross section in exclusive jet multiplicity and break down of the systematic uncertainties for the muon decay channel.}
\resizebox{\textwidth}{!}{
\begin{tabular}{c|cc|ccccccccccc}
\multicolumn{12}{c}{Exclusive jet multiplicity} \\

$N_{\text{jets}}$ & $\frac{d\sigma}{dN_{\text{jets}}} \tiny{\left[\text{pb}\right]}$ & \tiny{Tot. Unc [\%]} & \tiny{stat [\%]} & \tiny{Simulation stat [\%]} & \tiny{JES [\%]} & \tiny{JER [\%]} & \tiny{PU [\%]} & \tiny{XSEC [\%]} & \tiny{Lumi [\%]} & \tiny{BtagSF [\%]} & \tiny{Unf [\%]} & \tiny{Eff [\%]} \\\hline
= 0 & 7.43e+03 & 5.3 & 0.064 & 0.15 & 0.15 & 0.092 & 1.7 & 0.17 & 4.9 & 0.40 & 0.0 & 0.53 \\
= 1 & 867. & 5.6 & 0.28 & 0.69 & 1.4 & 0.43 & 1.3 & 0.25 & 5.2 & 0.82 & 0.0 & 0.56 \\
= 2 & 197. & 8.8 & 0.76 & 1.8 & 6.4 & 0.31 & 1.5 & 0.58 & 5.3 & 1.7 & 0.0 & 0.57 \\
= 3 & 44.8 & 13. & 1.9 & 4.2 & 8.7 & 0.74 & 3.3 & 1.9 & 5.9 & 2.8 & 0.0 & 0.64 \\
= 4 & 12.8 & 18. & 4.3 & 9.4 & 11. & 0.42 & 0.12 & 4.9 & 7.2 & 5.1 & 0.0 & 0.78 \\
= 5 & 1.76 & 41. & 14. & 27. & 21. & 0.12 & 2.1 & 11. & 11. & 11. & 0.0 & 1.1 \\
\end{tabular}}
\label{tab:DMuZNGoodJets_Zexc}
\end{center}\end{table}

\begin{table}[htb!]
\begin{center}
\caption{Differential cross section in inclusive jet multiplicity and break down of the systematic uncertainties for the muon decay channel.}
\resizebox{\textwidth}{!}{
\begin{tabular}{c|cc|ccccccccccc}
\multicolumn{12}{c}{Inclusive jet multiplicity} \\
$N_{\text{jets}}$ & $\frac{d\sigma}{dN_{\text{jets}}} \tiny{\left[\text{pb}\right]}$  & \tiny{Tot. Unc [\%]} & \tiny{stat [\%]} & \tiny{MC stat [\%]} & \tiny{JES [\%]} & \tiny{JER [\%]} & \tiny{PU [\%]} & \tiny{XSEC [\%]} & \tiny{Lumi [\%]} & \tiny{BtagSF [\%]} & \tiny{LER [\%]} & \tiny{Unf [\%]} & \tiny{Eff [\%]} \\ \hline
$\geq 0$ & 8.59e+03 & 5.3 & 0.056 & 0.15 & 0.53 & 0.024 & 1.7 & 0.19 & 4.9 & 0.48 & 0.0 & 0.54 \\
$\geq 1$ & 1.12e+03 & 7.9 & 0.32 & 0.55 & 5.6 & 0.15 & 1.3 & 0.42 & 5.2 & 1.1 & 0.0 & 0.57 \\
$\geq 2$ & 253. & 11. & 0.90 & 1.4 & 7.9 & 0.49 & 2.9 & 1.1 & 5.6 & 2.2 & 0.0 & 0.61 \\
$\geq 3$ & 59.1 & 15. & 2.3 & 3.2 & 11. & 1.1 & 2.5 & 3.1 & 6.5 & 4.0 & 0.0 & 0.71 \\
$\geq 4$ & 15.2 & 22. & 5.1 & 8.0 & 15. & 1.6 & 0.29 & 6.8 & 8.1 & 7.1 & 0.0 & 0.88 \\
$\geq 5$ & 2.65 & 42. & 14. & 18. & 26. & 2.3 & 1.5 & 14. & 12. & 15. & 0.0 & 1.3 \\
\end{tabular}
}
\label{tab:SMuZNGoodJetsFull_Zinc}
\end{center}\end{table}


\begin{figure}[hp]
    \includegraphics[width=0.5\textwidth]{SMu_unfolded_ZNGoodJetsFull_Zexc_Bayes_JetPtMin_30_JetEtaMax_24_MGPYTHIA6_.pdf}
    \includegraphics[width=0.5\textwidth]{SMu_unfolded_ZNGoodJetsFull_Zinc_Bayes_JetPtMin_30_JetEtaMax_24_MGPYTHIA6_.pdf}
    \caption{The differential cross section measurement for the exclusive and inclusive jet multiplicities, compared to the predictions of {\sc MadGraph5$\_$aMC@NLO} and MADGRAPH5. The black circular markers with the grey hatched band represent the unfolded data measurement and its total experimental uncertainty. The blue shaded band around the {\sc MadGraph5$\_$aMC@NLO} prediction represents its theoretical uncertainty including both statistical and systematical uncertainties. MADGRAPH5 is shown only with its statistical uncertainty. The lower panels show the ratios of the prediction to the unfolded data.}
    \label{fig:xsec_Njets_nlo}
\end{figure}


\chapter{Conclusions}
\section{Summary}
\section{Future Outlook}



\bibliographystyle{plain}

%\bibliographystyle{unsrt}
%\bibliographystyle{ieeetr}

\bibliography{thesisoutline_levine}

\end{document}